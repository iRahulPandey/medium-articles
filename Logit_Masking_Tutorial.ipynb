{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzWcN5oMnH4Zjg+NX1XeI6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfe86fc1aa964ab2900b7f9bd0e8b3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0ce1bbb6926484f9a9472f7034e5d61",
              "IPY_MODEL_3916ccd7071944be9489bee999a27482",
              "IPY_MODEL_99d1a6c062cc496f9e93a826a67c6c6f"
            ],
            "layout": "IPY_MODEL_33781e0b56654853bdce392005f74dd7"
          }
        },
        "c0ce1bbb6926484f9a9472f7034e5d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dff3ec237b74e83931dea7d9ee31f94",
            "placeholder": "​",
            "style": "IPY_MODEL_b3b7fb4e92d04326a72f3c18926cde0d",
            "value": "config.json: 100%"
          }
        },
        "3916ccd7071944be9489bee999a27482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dda2ad1f47b84e8585a718af73487674",
            "max": 878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a8953f6907349d082142f144269a89d",
            "value": 878
          }
        },
        "99d1a6c062cc496f9e93a826a67c6c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76bff504396c491c8574979ba3e41eb0",
            "placeholder": "​",
            "style": "IPY_MODEL_6f5eccb2f78c46078d4297f5660ae45c",
            "value": " 878/878 [00:00&lt;00:00, 46.9kB/s]"
          }
        },
        "33781e0b56654853bdce392005f74dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dff3ec237b74e83931dea7d9ee31f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3b7fb4e92d04326a72f3c18926cde0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dda2ad1f47b84e8585a718af73487674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a8953f6907349d082142f144269a89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76bff504396c491c8574979ba3e41eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5eccb2f78c46078d4297f5660ae45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c875cd88d70b404b8f448c40d0c88351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afca766baa054d698ce836f3cb9eecd6",
              "IPY_MODEL_d7f16dfcc5bc4dbbabc14d28f322a572",
              "IPY_MODEL_d4a04835ed0c4988b11f4465ae7ef82a"
            ],
            "layout": "IPY_MODEL_2c1d9f1b64664a9ea195eb132b3f024c"
          }
        },
        "afca766baa054d698ce836f3cb9eecd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2daa21283e4c7bb631115e990c26bc",
            "placeholder": "​",
            "style": "IPY_MODEL_1477ace698e343b5a03aeb1ed67e3b27",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "d7f16dfcc5bc4dbbabc14d28f322a572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2627f9310404040bb71f184cfa8010d",
            "max": 20919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba0493cf10254bc3be676f5abb16d5ea",
            "value": 20919
          }
        },
        "d4a04835ed0c4988b11f4465ae7ef82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_509858d556e1444191c12f6d7fbda6b0",
            "placeholder": "​",
            "style": "IPY_MODEL_fce3414398774eab9d040b17134b4e4d",
            "value": " 20.9k/20.9k [00:00&lt;00:00, 616kB/s]"
          }
        },
        "2c1d9f1b64664a9ea195eb132b3f024c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2daa21283e4c7bb631115e990c26bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1477ace698e343b5a03aeb1ed67e3b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2627f9310404040bb71f184cfa8010d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba0493cf10254bc3be676f5abb16d5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "509858d556e1444191c12f6d7fbda6b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce3414398774eab9d040b17134b4e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35dfaf6ce56d42c79b207fb882999d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5a71451c453459f84049ae144c90ec0",
              "IPY_MODEL_cf723761670c47afa312210dbe3c1957",
              "IPY_MODEL_50855950dcfb45139037ffd56d38c941"
            ],
            "layout": "IPY_MODEL_3a2629150f2e4a32a6c8c4ffce73cce0"
          }
        },
        "e5a71451c453459f84049ae144c90ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beadbccd13e3491b99483f894077eb42",
            "placeholder": "​",
            "style": "IPY_MODEL_6f13cf9d81bd4c23b2c9a9d6fc019f21",
            "value": "Fetching 2 files: 100%"
          }
        },
        "cf723761670c47afa312210dbe3c1957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f1951e9fa334227a09a8e84d8da633e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4da31424bfed414e94122b0b653693a1",
            "value": 2
          }
        },
        "50855950dcfb45139037ffd56d38c941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e4af7f172bf413886499c400742db02",
            "placeholder": "​",
            "style": "IPY_MODEL_a9c4a4ba44e343e6a5a2626ba8e1bad8",
            "value": " 2/2 [04:06&lt;00:00, 246.79s/it]"
          }
        },
        "3a2629150f2e4a32a6c8c4ffce73cce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beadbccd13e3491b99483f894077eb42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f13cf9d81bd4c23b2c9a9d6fc019f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f1951e9fa334227a09a8e84d8da633e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da31424bfed414e94122b0b653693a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e4af7f172bf413886499c400742db02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9c4a4ba44e343e6a5a2626ba8e1bad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e0f0bb014424dbeb61dfd58631c287b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65193e21a0c248a197fc1b92137f5725",
              "IPY_MODEL_6fefbd5ea2aa40db8fc69afa2d379bb4",
              "IPY_MODEL_c95b1a5e37624d0194f008208e2b4997"
            ],
            "layout": "IPY_MODEL_ad4651154d92497c8221be63dab80e9e"
          }
        },
        "65193e21a0c248a197fc1b92137f5725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc9380fe7a384e6982cf8e7e693419d9",
            "placeholder": "​",
            "style": "IPY_MODEL_e0217059e1f04db9bb75ded5fc00208e",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "6fefbd5ea2aa40db8fc69afa2d379bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef4928a057a45919d943012670a4d8e",
            "max": 4965799096,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d46de25319dc4d06a003d585b0334fb7",
            "value": 4965799096
          }
        },
        "c95b1a5e37624d0194f008208e2b4997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b86f4b151dd466e97ce155a5b5f1a38",
            "placeholder": "​",
            "style": "IPY_MODEL_f5860059e3c741acaac88d7aa6b2ba1b",
            "value": " 4.97G/4.97G [04:06&lt;00:00, 42.1MB/s]"
          }
        },
        "ad4651154d92497c8221be63dab80e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9380fe7a384e6982cf8e7e693419d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0217059e1f04db9bb75ded5fc00208e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ef4928a057a45919d943012670a4d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46de25319dc4d06a003d585b0334fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b86f4b151dd466e97ce155a5b5f1a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5860059e3c741acaac88d7aa6b2ba1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "171d5c58f8454d2e819c20462949be1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfb3cc04cdcb49cf8b0e27c8d8e1477a",
              "IPY_MODEL_3697352e904f4718b9a6cd51bb2f4ff6",
              "IPY_MODEL_59756a22378b497aaeebce569ce76b9c"
            ],
            "layout": "IPY_MODEL_454dac7f85fa4fa9bae4472f6922e43c"
          }
        },
        "cfb3cc04cdcb49cf8b0e27c8d8e1477a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb55674d02f4321b870333afd441260",
            "placeholder": "​",
            "style": "IPY_MODEL_0a7af924ed064ae0bc390d9a06a40474",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "3697352e904f4718b9a6cd51bb2f4ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_982fbb78e5b54a75985a4211d013b915",
            "max": 1459729952,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20f6789d12f849cfa17f2c26b1dd4c94",
            "value": 1459729952
          }
        },
        "59756a22378b497aaeebce569ce76b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_575eddd427f34c9dbfd02c04eaf47bc5",
            "placeholder": "​",
            "style": "IPY_MODEL_6fb9b912e4d644309d60f7fbb4301c9a",
            "value": " 1.46G/1.46G [03:11&lt;00:00, 2.49MB/s]"
          }
        },
        "454dac7f85fa4fa9bae4472f6922e43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbb55674d02f4321b870333afd441260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a7af924ed064ae0bc390d9a06a40474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "982fbb78e5b54a75985a4211d013b915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20f6789d12f849cfa17f2c26b1dd4c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "575eddd427f34c9dbfd02c04eaf47bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb9b912e4d644309d60f7fbb4301c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "695cd97bdb874f65bfcee4cbd1e03a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37ff8f28e8af4e35bc9cbd47f7ea6d85",
              "IPY_MODEL_b3b78c80d96e4df99468220fc0a2728b",
              "IPY_MODEL_fc2b65023a2b469a8c72fdd014760434"
            ],
            "layout": "IPY_MODEL_13d47acba8bf4fc5a1deb9f6e7d752bb"
          }
        },
        "37ff8f28e8af4e35bc9cbd47f7ea6d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f23f51cfac624badb92d3d7cfcbc4a6c",
            "placeholder": "​",
            "style": "IPY_MODEL_5e843babd7da4b078ca72dae86c887a5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b3b78c80d96e4df99468220fc0a2728b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_104963f456ba4b83818fe3849d96c79f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc33fe955cef490db4d17917bb6cb53f",
            "value": 2
          }
        },
        "fc2b65023a2b469a8c72fdd014760434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7292be25550143f39cdec5f556b16cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_34c9e9b3076c4fc58ea30a367498276f",
            "value": " 2/2 [00:30&lt;00:00, 13.66s/it]"
          }
        },
        "13d47acba8bf4fc5a1deb9f6e7d752bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23f51cfac624badb92d3d7cfcbc4a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e843babd7da4b078ca72dae86c887a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "104963f456ba4b83818fe3849d96c79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc33fe955cef490db4d17917bb6cb53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7292be25550143f39cdec5f556b16cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c9e9b3076c4fc58ea30a367498276f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2331a54a741b41c397a8004bae44f0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_887a9f9549ce489a9194102a0d45d578",
              "IPY_MODEL_6d77b398b7014bc796c666c050343f0f",
              "IPY_MODEL_bec45317e71540f49dd6d056f56b53d9"
            ],
            "layout": "IPY_MODEL_6353bfdb6cae446d99d44c7d803b50fe"
          }
        },
        "887a9f9549ce489a9194102a0d45d578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3dc8a45d831434a8a941c1112ff47a2",
            "placeholder": "​",
            "style": "IPY_MODEL_4304c1332b114d82be3b6e531ac997fa",
            "value": "generation_config.json: 100%"
          }
        },
        "6d77b398b7014bc796c666c050343f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d66644fde8894de3be791b4299c836da",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_150719759a08438da9d2d00847039bf6",
            "value": 189
          }
        },
        "bec45317e71540f49dd6d056f56b53d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d108f78afcda4f0ea6505ec4ff17d175",
            "placeholder": "​",
            "style": "IPY_MODEL_64a9ee10121a414298cae0faccf08c2e",
            "value": " 189/189 [00:00&lt;00:00, 20.3kB/s]"
          }
        },
        "6353bfdb6cae446d99d44c7d803b50fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3dc8a45d831434a8a941c1112ff47a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4304c1332b114d82be3b6e531ac997fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d66644fde8894de3be791b4299c836da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "150719759a08438da9d2d00847039bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d108f78afcda4f0ea6505ec4ff17d175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a9ee10121a414298cae0faccf08c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "335db0e3051c44059093d78fec8fd137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2cb34b4e595459ea9d9cae0ea59befa",
              "IPY_MODEL_e5356b1a182a468f897725956a250966",
              "IPY_MODEL_abe8770332c348d285068ade04a57718"
            ],
            "layout": "IPY_MODEL_81a9b5a71c464b7d9a43ec0d72b8b7c3"
          }
        },
        "f2cb34b4e595459ea9d9cae0ea59befa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_423a3b26f2604e65b52492fb2907f205",
            "placeholder": "​",
            "style": "IPY_MODEL_f7cc301763b1458cb778bca18874aba8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e5356b1a182a468f897725956a250966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb6a85944614d83aca097d661187ab3",
            "max": 54528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca9627afccea439c824aaf4d18fe2e38",
            "value": 54528
          }
        },
        "abe8770332c348d285068ade04a57718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_144e101ac9df4832823e13b5bb6a432e",
            "placeholder": "​",
            "style": "IPY_MODEL_63d85da4a3954f8c833bf5dc42f13821",
            "value": " 54.5k/54.5k [00:00&lt;00:00, 5.71MB/s]"
          }
        },
        "81a9b5a71c464b7d9a43ec0d72b8b7c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423a3b26f2604e65b52492fb2907f205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7cc301763b1458cb778bca18874aba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb6a85944614d83aca097d661187ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9627afccea439c824aaf4d18fe2e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "144e101ac9df4832823e13b5bb6a432e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d85da4a3954f8c833bf5dc42f13821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2c1f94f22994d2c829c89d8c3ad0033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a82023d27bd4804bd05ec84da119b0f",
              "IPY_MODEL_c7751ce830af4eddbdde7fb1af9e74a4",
              "IPY_MODEL_35e15c61c4db4813b2fa35792e86196b"
            ],
            "layout": "IPY_MODEL_af9a7d92cc3c4f7d8bf28a54b74c13c9"
          }
        },
        "4a82023d27bd4804bd05ec84da119b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27efc9c8d5c74982a4d31c701b97388f",
            "placeholder": "​",
            "style": "IPY_MODEL_16e37392f8da45b0998f46c944461393",
            "value": "tokenizer.json: 100%"
          }
        },
        "c7751ce830af4eddbdde7fb1af9e74a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb2411b8de644202b0d86eabba9a824e",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb675cfa79a44314a7d8e94013932224",
            "value": 9085657
          }
        },
        "35e15c61c4db4813b2fa35792e86196b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b294468280b47d384ffd7dd99ec5278",
            "placeholder": "​",
            "style": "IPY_MODEL_617287e3357e441b87266f3d27d41d93",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 27.0MB/s]"
          }
        },
        "af9a7d92cc3c4f7d8bf28a54b74c13c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27efc9c8d5c74982a4d31c701b97388f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16e37392f8da45b0998f46c944461393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb2411b8de644202b0d86eabba9a824e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb675cfa79a44314a7d8e94013932224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b294468280b47d384ffd7dd99ec5278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "617287e3357e441b87266f3d27d41d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dab50a3ed25f4e1fb16d35ace7c88cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ad4c56567654a9da38dadc6f8b1da24",
              "IPY_MODEL_078a5f4c1c854dfe9a87c4ffdc0934a7",
              "IPY_MODEL_b9cfc624ae4046239d836b2bb4dde6b0"
            ],
            "layout": "IPY_MODEL_33a3c5a548244ab2b213938d360f753f"
          }
        },
        "5ad4c56567654a9da38dadc6f8b1da24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4ba6fa1c1d041ca984383d47e1f8598",
            "placeholder": "​",
            "style": "IPY_MODEL_4da41de8d55f46948f31c07b17bd6180",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "078a5f4c1c854dfe9a87c4ffdc0934a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f6f53dbf2047aabe0eeddf20e3ee73",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fa1f6a786a547c3b58208b94790c4c0",
            "value": 296
          }
        },
        "b9cfc624ae4046239d836b2bb4dde6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9af8bebffa4d486dad2280f212f2d659",
            "placeholder": "​",
            "style": "IPY_MODEL_bbb5dc18f1d74ea7a6d90e00a32805ec",
            "value": " 296/296 [00:00&lt;00:00, 35.1kB/s]"
          }
        },
        "33a3c5a548244ab2b213938d360f753f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4ba6fa1c1d041ca984383d47e1f8598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da41de8d55f46948f31c07b17bd6180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3f6f53dbf2047aabe0eeddf20e3ee73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa1f6a786a547c3b58208b94790c4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9af8bebffa4d486dad2280f212f2d659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbb5dc18f1d74ea7a6d90e00a32805ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iRahulPandey/medium-articles/blob/master/Logit_Masking_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DZLdactKBmn"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Logit Masking Tutorial: Understanding and Controlling LLM Text Generation\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. How LLMs generate text (deterministic computation + random sampling)\n",
        "2. Traditional control methods (temperature, top-k, top-p)\n",
        "3. Their limitations for guaranteed compliance\n",
        "4. Logit masking as a solution for hard constraints\n",
        "\n",
        "Author: Rahul Pandey\n",
        "Date: 2025\n",
        "Model: Llama 3.2 3B Instruct\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SETUP AND IMPORTS\n",
        "# ============================================================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install --upgrade --quiet transformers torch accelerate bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kByGMLYMGU5",
        "outputId": "6e42e46d-83a0-48e0-ced7-ca460c01c0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "from transformers import pipeline, LogitsProcessor\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "_JHBQCpzMK0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MODEL INITIALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def setup_model_pipeline():\n",
        "    \"\"\"\n",
        "    Initialize Llama 3.2 3B Instruct model with automatic device detection.\n",
        "\n",
        "    Purpose:\n",
        "        - Detect available hardware (GPU/CPU)\n",
        "        - Configure optimal settings for available hardware\n",
        "        - Load model with appropriate quantization\n",
        "\n",
        "    Returns:\n",
        "        tuple: (pipeline, device_info)\n",
        "            - pipeline: Hugging Face text generation pipeline\n",
        "            - device_info: dict with hardware information\n",
        "\n",
        "    Expected Output:\n",
        "        Prints device information and model loading status\n",
        "        Returns configured pipeline ready for inference\n",
        "\n",
        "    Notes:\n",
        "        - GPU: Uses 4-bit quantization for memory efficiency\n",
        "        - CPU: Uses float32 (slower but functional)\n",
        "        - Requires HF_TOKEN in Colab secrets for gated models\n",
        "    \"\"\"\n",
        "\n",
        "    MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "    # Check available hardware\n",
        "    device_info = {\n",
        "        'has_cuda': torch.cuda.is_available(),\n",
        "        'device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
        "        'current_device': torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "\n",
        "    # Display hardware information\n",
        "    print(f\"Device Detection:\")\n",
        "    print(f\"   CUDA Available: {device_info['has_cuda']}\")\n",
        "    if device_info['has_cuda']:\n",
        "        print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
        "        print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    else:\n",
        "        print(f\"   Running on CPU (will be slower)\")\n",
        "\n",
        "    # Get HuggingFace authentication token\n",
        "    try:\n",
        "        hf_token = userdata.get('HF_TOKEN')\n",
        "        print(\"HuggingFace token loaded\")\n",
        "    except:\n",
        "        print(\"WARNING: HF_TOKEN not found in secrets\")\n",
        "        print(\"Add your token in Colab: Secrets -> Add Secret -> Name: HF_TOKEN\")\n",
        "        raise ValueError(\"HF_TOKEN required for gated models\")\n",
        "\n",
        "    # Base pipeline configuration\n",
        "    pipeline_config = {\n",
        "        \"task\": \"text-generation\",\n",
        "        \"model\": MODEL_ID,\n",
        "        \"token\": hf_token,\n",
        "        \"trust_remote_code\": True\n",
        "    }\n",
        "\n",
        "    # Hardware-specific optimizations\n",
        "    if device_info['has_cuda']:\n",
        "        # GPU configuration: 4-bit quantization for efficiency\n",
        "        pipeline_config.update({\n",
        "            \"torch_dtype\": torch.bfloat16,\n",
        "            \"device_map\": \"auto\",\n",
        "            \"model_kwargs\": {\n",
        "                \"quantization_config\": {\n",
        "                    \"load_in_4bit\": True,\n",
        "                    \"bnb_4bit_use_double_quant\": True,\n",
        "                    \"bnb_4bit_quant_type\": \"nf4\",\n",
        "                    \"bnb_4bit_compute_dtype\": torch.bfloat16\n",
        "                }\n",
        "            }\n",
        "        })\n",
        "        print(\"Optimizing for GPU with 4-bit quantization\")\n",
        "    else:\n",
        "        # CPU configuration: Standard float32\n",
        "        pipeline_config.update({\n",
        "            \"torch_dtype\": torch.float32,\n",
        "            \"device_map\": \"cpu\"\n",
        "        })\n",
        "        print(\"Optimizing for CPU (slower but functional)\")\n",
        "\n",
        "    # Load the model\n",
        "    print(\"Loading model... (this may take 2-3 minutes)\")\n",
        "    pipe = pipeline(**pipeline_config)\n",
        "\n",
        "    print(f\"Model loaded successfully!\")\n",
        "    print(f\"Model device: {pipe.model.device}\")\n",
        "\n",
        "    return pipe, device_info\n",
        "\n",
        "def get_model_device():\n",
        "    \"\"\"\n",
        "    Get the device where the model is currently loaded.\n",
        "\n",
        "    Purpose:\n",
        "        Dynamically determine device for tensor operations to avoid\n",
        "        device mismatch errors when moving tensors between CPU/GPU.\n",
        "\n",
        "    Returns:\n",
        "        torch.device: Device where model resides (cuda:0 or cpu)\n",
        "\n",
        "    Notes:\n",
        "        - Checks multiple attributes for compatibility\n",
        "        - Handles device_map=\"auto\" configuration\n",
        "        - Falls back to CUDA check if attributes missing\n",
        "    \"\"\"\n",
        "    if hasattr(pipe.model, 'device'):\n",
        "        return pipe.model.device\n",
        "    elif hasattr(pipe.model, 'hf_device_map'):\n",
        "        # For device_map=\"auto\", get device of first layer\n",
        "        first_device = next(iter(pipe.model.hf_device_map.values()))\n",
        "        return torch.device(first_device)\n",
        "    else:\n",
        "        # Fallback to CUDA availability check\n",
        "        return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the pipeline (global variable for notebook)\n",
        "pipe, device_info = setup_model_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533,
          "referenced_widgets": [
            "cfe86fc1aa964ab2900b7f9bd0e8b3c7",
            "c0ce1bbb6926484f9a9472f7034e5d61",
            "3916ccd7071944be9489bee999a27482",
            "99d1a6c062cc496f9e93a826a67c6c6f",
            "33781e0b56654853bdce392005f74dd7",
            "8dff3ec237b74e83931dea7d9ee31f94",
            "b3b7fb4e92d04326a72f3c18926cde0d",
            "dda2ad1f47b84e8585a718af73487674",
            "5a8953f6907349d082142f144269a89d",
            "76bff504396c491c8574979ba3e41eb0",
            "6f5eccb2f78c46078d4297f5660ae45c",
            "c875cd88d70b404b8f448c40d0c88351",
            "afca766baa054d698ce836f3cb9eecd6",
            "d7f16dfcc5bc4dbbabc14d28f322a572",
            "d4a04835ed0c4988b11f4465ae7ef82a",
            "2c1d9f1b64664a9ea195eb132b3f024c",
            "2d2daa21283e4c7bb631115e990c26bc",
            "1477ace698e343b5a03aeb1ed67e3b27",
            "d2627f9310404040bb71f184cfa8010d",
            "ba0493cf10254bc3be676f5abb16d5ea",
            "509858d556e1444191c12f6d7fbda6b0",
            "fce3414398774eab9d040b17134b4e4d",
            "35dfaf6ce56d42c79b207fb882999d98",
            "e5a71451c453459f84049ae144c90ec0",
            "cf723761670c47afa312210dbe3c1957",
            "50855950dcfb45139037ffd56d38c941",
            "3a2629150f2e4a32a6c8c4ffce73cce0",
            "beadbccd13e3491b99483f894077eb42",
            "6f13cf9d81bd4c23b2c9a9d6fc019f21",
            "9f1951e9fa334227a09a8e84d8da633e",
            "4da31424bfed414e94122b0b653693a1",
            "9e4af7f172bf413886499c400742db02",
            "a9c4a4ba44e343e6a5a2626ba8e1bad8",
            "6e0f0bb014424dbeb61dfd58631c287b",
            "65193e21a0c248a197fc1b92137f5725",
            "6fefbd5ea2aa40db8fc69afa2d379bb4",
            "c95b1a5e37624d0194f008208e2b4997",
            "ad4651154d92497c8221be63dab80e9e",
            "fc9380fe7a384e6982cf8e7e693419d9",
            "e0217059e1f04db9bb75ded5fc00208e",
            "7ef4928a057a45919d943012670a4d8e",
            "d46de25319dc4d06a003d585b0334fb7",
            "6b86f4b151dd466e97ce155a5b5f1a38",
            "f5860059e3c741acaac88d7aa6b2ba1b",
            "171d5c58f8454d2e819c20462949be1a",
            "cfb3cc04cdcb49cf8b0e27c8d8e1477a",
            "3697352e904f4718b9a6cd51bb2f4ff6",
            "59756a22378b497aaeebce569ce76b9c",
            "454dac7f85fa4fa9bae4472f6922e43c",
            "cbb55674d02f4321b870333afd441260",
            "0a7af924ed064ae0bc390d9a06a40474",
            "982fbb78e5b54a75985a4211d013b915",
            "20f6789d12f849cfa17f2c26b1dd4c94",
            "575eddd427f34c9dbfd02c04eaf47bc5",
            "6fb9b912e4d644309d60f7fbb4301c9a",
            "695cd97bdb874f65bfcee4cbd1e03a4a",
            "37ff8f28e8af4e35bc9cbd47f7ea6d85",
            "b3b78c80d96e4df99468220fc0a2728b",
            "fc2b65023a2b469a8c72fdd014760434",
            "13d47acba8bf4fc5a1deb9f6e7d752bb",
            "f23f51cfac624badb92d3d7cfcbc4a6c",
            "5e843babd7da4b078ca72dae86c887a5",
            "104963f456ba4b83818fe3849d96c79f",
            "fc33fe955cef490db4d17917bb6cb53f",
            "7292be25550143f39cdec5f556b16cf6",
            "34c9e9b3076c4fc58ea30a367498276f",
            "2331a54a741b41c397a8004bae44f0a8",
            "887a9f9549ce489a9194102a0d45d578",
            "6d77b398b7014bc796c666c050343f0f",
            "bec45317e71540f49dd6d056f56b53d9",
            "6353bfdb6cae446d99d44c7d803b50fe",
            "e3dc8a45d831434a8a941c1112ff47a2",
            "4304c1332b114d82be3b6e531ac997fa",
            "d66644fde8894de3be791b4299c836da",
            "150719759a08438da9d2d00847039bf6",
            "d108f78afcda4f0ea6505ec4ff17d175",
            "64a9ee10121a414298cae0faccf08c2e",
            "335db0e3051c44059093d78fec8fd137",
            "f2cb34b4e595459ea9d9cae0ea59befa",
            "e5356b1a182a468f897725956a250966",
            "abe8770332c348d285068ade04a57718",
            "81a9b5a71c464b7d9a43ec0d72b8b7c3",
            "423a3b26f2604e65b52492fb2907f205",
            "f7cc301763b1458cb778bca18874aba8",
            "3bb6a85944614d83aca097d661187ab3",
            "ca9627afccea439c824aaf4d18fe2e38",
            "144e101ac9df4832823e13b5bb6a432e",
            "63d85da4a3954f8c833bf5dc42f13821",
            "d2c1f94f22994d2c829c89d8c3ad0033",
            "4a82023d27bd4804bd05ec84da119b0f",
            "c7751ce830af4eddbdde7fb1af9e74a4",
            "35e15c61c4db4813b2fa35792e86196b",
            "af9a7d92cc3c4f7d8bf28a54b74c13c9",
            "27efc9c8d5c74982a4d31c701b97388f",
            "16e37392f8da45b0998f46c944461393",
            "eb2411b8de644202b0d86eabba9a824e",
            "cb675cfa79a44314a7d8e94013932224",
            "3b294468280b47d384ffd7dd99ec5278",
            "617287e3357e441b87266f3d27d41d93",
            "dab50a3ed25f4e1fb16d35ace7c88cb1",
            "5ad4c56567654a9da38dadc6f8b1da24",
            "078a5f4c1c854dfe9a87c4ffdc0934a7",
            "b9cfc624ae4046239d836b2bb4dde6b0",
            "33a3c5a548244ab2b213938d360f753f",
            "d4ba6fa1c1d041ca984383d47e1f8598",
            "4da41de8d55f46948f31c07b17bd6180",
            "a3f6f53dbf2047aabe0eeddf20e3ee73",
            "0fa1f6a786a547c3b58208b94790c4c0",
            "9af8bebffa4d486dad2280f212f2d659",
            "bbb5dc18f1d74ea7a6d90e00a32805ec"
          ]
        },
        "id": "NsHF0gtuMPzh",
        "outputId": "84a5b448-efce-4a2a-dd52-1f2df4d20248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Detection:\n",
            "   CUDA Available: True\n",
            "   GPU: Tesla T4\n",
            "   GPU Memory: 15.8 GB\n",
            "HuggingFace token loaded\n",
            "Optimizing for GPU with 4-bit quantization\n",
            "Loading model... (this may take 2-3 minutes)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfe86fc1aa964ab2900b7f9bd0e8b3c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c875cd88d70b404b8f448c40d0c88351"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35dfaf6ce56d42c79b207fb882999d98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e0f0bb014424dbeb61dfd58631c287b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "171d5c58f8454d2e819c20462949be1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "695cd97bdb874f65bfcee4cbd1e03a4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2331a54a741b41c397a8004bae44f0a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "335db0e3051c44059093d78fec8fd137"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2c1f94f22994d2c829c89d8c3ad0033"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dab50a3ed25f4e1fb16d35ace7c88cb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n",
            "Model device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 1: UNDERSTANDING DETERMINISM\n",
        "# ============================================================================\n",
        "\n",
        "def peek_inside_ai_brain(prompt):\n",
        "    \"\"\"\n",
        "    Reveal the deterministic probability distribution computed by the model.\n",
        "\n",
        "    Purpose:\n",
        "        Demonstrate that language models compute the exact same probabilities\n",
        "        for the same input every time. The \"intelligence\" is in these fixed\n",
        "        probabilities, not in random choices.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text to analyze\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Full probability distribution over vocabulary\n",
        "                     (shape: [vocab_size])\n",
        "\n",
        "    Expected Output:\n",
        "        Prints top 10 most probable next tokens with their probabilities.\n",
        "        Returns complete probability distribution for further analysis.\n",
        "\n",
        "    Example:\n",
        "        >>> peek_inside_ai_brain(\"This luxury watch is\")\n",
        "        Deterministic probability distribution:\n",
        "           1. ' a'            : 18.2%\n",
        "           2. ' the'          : 15.7%\n",
        "           ...\n",
        "\n",
        "    Notes:\n",
        "        - Forward pass is pure function: same input -> same output\n",
        "        - Probabilities sum to 1.0\n",
        "        - Distribution does NOT change between runs\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Analyzing AI thoughts for: '{prompt}'\")\n",
        "\n",
        "    # Get model's device for tensor operations\n",
        "    model_device = get_model_device()\n",
        "\n",
        "    # Tokenize input and move to model's device\n",
        "    inputs = pipe.tokenizer.encode(prompt, return_tensors='pt')\n",
        "    inputs = inputs.to(model_device)\n",
        "\n",
        "    # Forward pass through transformer (deterministic computation)\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            outputs = pipe.model(inputs)\n",
        "            # Get logits for the last position (next token prediction)\n",
        "            logits = outputs.logits[0, -1]\n",
        "        except Exception as e:\n",
        "            print(f\"Error in forward pass: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Convert logits to probabilities using softmax (still deterministic)\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    # Get top 10 most probable tokens\n",
        "    top_probs, top_indices = torch.topk(probabilities, 10)\n",
        "\n",
        "    # Display results\n",
        "    print(\"Deterministic probability distribution:\")\n",
        "    print(\"-\" * 50)\n",
        "    for i, (prob, token_id) in enumerate(zip(top_probs, top_indices)):\n",
        "        token = pipe.tokenizer.decode([token_id])\n",
        "        confidence = prob.item() * 100\n",
        "        # Visual bar chart (each █ = 5%)\n",
        "        bar = \"█\" * max(1, int(confidence / 5))\n",
        "        print(f\"  {i+1:2d}. '{token:15s}': {confidence:5.1f}% {bar}\")\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "def test_determinism(prompt=\"This luxury watch is\"):\n",
        "    \"\"\"\n",
        "    Prove that model computations are 100% deterministic.\n",
        "\n",
        "    Purpose:\n",
        "        Experimentally verify that the model produces identical probability\n",
        "        distributions for the same input across multiple runs.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Test input text\n",
        "\n",
        "    Returns:\n",
        "        bool: True if calculations are identical, False otherwise\n",
        "\n",
        "    Expected Output:\n",
        "        Prints two probability distributions and verifies they are identical\n",
        "        within numerical precision (1e-6).\n",
        "\n",
        "    Key Insight:\n",
        "        If this returns True (it will), it proves that all \"intelligence\"\n",
        "        is in the deterministic computation, NOT in random selection.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"TESTING AI DETERMINISM\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # First calculation\n",
        "        print(\"First calculation:\")\n",
        "        probs1 = peek_inside_ai_brain(prompt)\n",
        "\n",
        "        if probs1 is None:\n",
        "            print(\"Failed to get probabilities\")\n",
        "            return False\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "\n",
        "        # Second calculation (should be identical)\n",
        "        print(\"Second calculation (should be identical):\")\n",
        "        probs2 = peek_inside_ai_brain(prompt)\n",
        "\n",
        "        if probs2 is None:\n",
        "            print(\"Failed to get probabilities\")\n",
        "            return False\n",
        "\n",
        "        # Verify identical calculations (within floating point precision)\n",
        "        identical = torch.allclose(probs1, probs2, atol=1e-6)\n",
        "\n",
        "        print(f\"\\nRESULT:\")\n",
        "        if identical:\n",
        "            print(f\"   Calculations identical: {identical} ✅\")\n",
        "            print(\"   This proves AI 'thinking' is 100% deterministic!\")\n",
        "            print(\"   Randomness only comes from the sampling step\")\n",
        "        else:\n",
        "            print(f\"   Calculations identical: {identical} ❌\")\n",
        "            print(\"   Unexpected! Check for hardware issues or precision errors\")\n",
        "\n",
        "        return identical\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in determinism test: {e}\")\n",
        "        return False\n",
        "\n",
        "# Run the determinism test\n",
        "determinism_verified = test_determinism()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6PzvjJ-MZ8Z",
        "outputId": "ebbb955c-98c1-4ad1-c4bc-5f7e8c39b54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TESTING AI DETERMINISM\n",
            "============================================================\n",
            "First calculation:\n",
            "Analyzing AI thoughts for: 'This luxury watch is'\n",
            "Deterministic probability distribution:\n",
            "--------------------------------------------------\n",
            "   1. ' a             ':  37.5% ███████\n",
            "   2. ' designed      ':   9.5% █\n",
            "   3. ' made          ':   8.4% █\n",
            "   4. ' crafted       ':   5.4% █\n",
            "   5. ' inspired      ':   3.7% █\n",
            "   6. ' part          ':   3.1% █\n",
            "   7. ' adorned       ':   2.4% █\n",
            "   8. ' an            ':   2.0% █\n",
            "   9. ' the           ':   2.0% █\n",
            "  10. ' not           ':   1.9% █\n",
            "\n",
            "==================================================\n",
            "Second calculation (should be identical):\n",
            "Analyzing AI thoughts for: 'This luxury watch is'\n",
            "Deterministic probability distribution:\n",
            "--------------------------------------------------\n",
            "   1. ' a             ':  37.5% ███████\n",
            "   2. ' designed      ':   9.5% █\n",
            "   3. ' made          ':   8.4% █\n",
            "   4. ' crafted       ':   5.4% █\n",
            "   5. ' inspired      ':   3.7% █\n",
            "   6. ' part          ':   3.1% █\n",
            "   7. ' adorned       ':   2.4% █\n",
            "   8. ' an            ':   2.0% █\n",
            "   9. ' the           ':   2.0% █\n",
            "  10. ' not           ':   1.9% █\n",
            "\n",
            "RESULT:\n",
            "   Calculations identical: True ✅\n",
            "   This proves AI 'thinking' is 100% deterministic!\n",
            "   Randomness only comes from the sampling step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 2: WHERE RANDOMNESS ENTERS\n",
        "# ============================================================================\n",
        "\n",
        "def demonstrate_sampling_randomness(prompt, num_samples=5):\n",
        "    \"\"\"\n",
        "    Show that randomness exists ONLY in the sampling step, not computation.\n",
        "\n",
        "    Purpose:\n",
        "        Demonstrate that the same probability distribution can produce\n",
        "        different outputs through random sampling. This is where variety\n",
        "        and creativity come from.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text to continue\n",
        "        num_samples (int): Number of different samples to generate\n",
        "\n",
        "    Expected Output:\n",
        "        Prints multiple completions that are different despite using\n",
        "        the exact same probability distribution.\n",
        "\n",
        "    Key Insight:\n",
        "        Same input -> Same probabilities (deterministic)\n",
        "        Same probabilities -> Different samples (random)\n",
        "\n",
        "    Example Output:\n",
        "        Sample 1: 'This luxury watch is a testament to precision'\n",
        "        Sample 2: 'This luxury watch is the epitome of craftsmanship'\n",
        "        Sample 3: 'This luxury watch is designed for collectors'\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"SAMPLING RANDOMNESS DEMONSTRATION\")\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Get model device\n",
        "    model_device = get_model_device()\n",
        "\n",
        "    # Tokenize and move to model device\n",
        "    inputs = pipe.tokenizer.encode(prompt, return_tensors='pt')\n",
        "    inputs = inputs.to(model_device)\n",
        "\n",
        "    print(\"Sampling from the SAME deterministic probability distribution:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        try:\n",
        "            # Same deterministic forward pass every time\n",
        "            with torch.no_grad():\n",
        "                output = pipe.model.generate(\n",
        "                    inputs,\n",
        "                    max_new_tokens=8,\n",
        "                    do_sample=True,  # THIS is where randomness enters\n",
        "                    temperature=1.0,\n",
        "                    pad_token_id=pipe.tokenizer.eos_token_id,\n",
        "                    eos_token_id=pipe.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            # Decode only the newly generated tokens\n",
        "            generated = pipe.tokenizer.decode(\n",
        "                output[0][len(inputs[0]):],\n",
        "                skip_special_tokens=True\n",
        "            )\n",
        "\n",
        "            print(f\"  Sample {i+1}: '{prompt}{generated.strip()}'\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Sample {i+1}: Generation failed: {e}\")\n",
        "\n",
        "    print(f\"\\nKey Insight:\")\n",
        "    print(f\"   • Same input → Same probabilities (deterministic)\")\n",
        "    print(f\"   • Same probabilities → Different samples (random)\")\n",
        "    print(f\"   • Randomness exists ONLY in the sampling step!\")\n",
        "\n",
        "# Demonstrate sampling randomness\n",
        "demonstrate_sampling_randomness(\"This luxury watch is \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4D-MK6xMvYz",
        "outputId": "29ce7562-30fd-4d64-ae00-3f8e71fca26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLING RANDOMNESS DEMONSTRATION\n",
            "Prompt: 'This luxury watch is '\n",
            "============================================================\n",
            "Sampling from the SAME deterministic probability distribution:\n",
            "--------------------------------------------------\n",
            "  Sample 1: 'This luxury watch is 40 mm in diameter. It features a'\n",
            "  Sample 2: 'This luxury watch is 42 mm in diameter, 12.'\n",
            "  Sample 3: 'This luxury watch is 18k gold and engraved with 3'\n",
            "  Sample 4: 'This luxury watch is 40mm in size, made of platinum'\n",
            "  Sample 5: 'This luxury watch is 18K rose gold and 18K'\n",
            "\n",
            "Key Insight:\n",
            "   • Same input → Same probabilities (deterministic)\n",
            "   • Same probabilities → Different samples (random)\n",
            "   • Randomness exists ONLY in the sampling step!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 3: TRADITIONAL CONTROL METHOD 1 - TEMPERATURE\n",
        "# ============================================================================\n",
        "\n",
        "def demonstrate_temperature_effects(prompt, temperatures=[0.1, 1.0, 2.0]):\n",
        "    \"\"\"\n",
        "    Show how temperature reshapes the probability distribution.\n",
        "\n",
        "    Purpose:\n",
        "        Demonstrate that temperature is a style control that changes the\n",
        "        \"sharpness\" of the probability distribution before sampling.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text\n",
        "        temperatures (list): Temperature values to test\n",
        "\n",
        "    Temperature Effects:\n",
        "        - T < 1.0: Sharper distribution (more confident/conservative)\n",
        "        - T = 1.0: Original distribution (balanced)\n",
        "        - T > 1.0: Flatter distribution (more creative/risky)\n",
        "\n",
        "    Expected Output:\n",
        "        Shows how the same logits produce different probability distributions\n",
        "        when divided by different temperature values.\n",
        "\n",
        "    Mathematical Formula:\n",
        "        probs = softmax(logits / temperature)\n",
        "\n",
        "    Limitation:\n",
        "        Even at very low temperature, unwanted tokens still have\n",
        "        non-zero probability!\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"TEMPERATURE EFFECTS DEMONSTRATION\")\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Get model device and prepare inputs\n",
        "    model_device = get_model_device()\n",
        "    inputs = pipe.tokenizer.encode(prompt, return_tensors='pt').to(model_device)\n",
        "\n",
        "    try:\n",
        "        # Get base logits (always identical for same input)\n",
        "        with torch.no_grad():\n",
        "            outputs = pipe.model(inputs)\n",
        "            base_logits = outputs.logits[0, -1]\n",
        "\n",
        "        for temp in temperatures:\n",
        "            print(f\"\\nTemperature {temp:3.1f}:\")\n",
        "\n",
        "            # Apply temperature scaling: divide logits by temperature\n",
        "            scaled_logits = base_logits / temp\n",
        "            probs = torch.softmax(scaled_logits, dim=-1)\n",
        "            top_probs, top_indices = torch.topk(probs, 5)\n",
        "\n",
        "            # Calculate distribution entropy (measure of uncertainty)\n",
        "            entropy = -(probs * torch.log(probs + 1e-10)).sum().item()\n",
        "\n",
        "            print(f\"   Distribution sharpness (entropy): {entropy:.2f}\")\n",
        "            print(\"   Top 5 tokens:\")\n",
        "\n",
        "            for i, (prob, token_id) in enumerate(zip(top_probs, top_indices)):\n",
        "                token = pipe.tokenizer.decode([token_id])\n",
        "                percentage = prob.item() * 100\n",
        "                bar = \"█\" * max(1, int(percentage / 4))\n",
        "                print(f\"     {token:12s}: {percentage:5.1f}% {bar}\")\n",
        "\n",
        "            # Show concentration of probability mass\n",
        "            top_5_mass = top_probs.sum().item() * 100\n",
        "            print(f\"   Top 5 probability mass: {top_5_mass:.1f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Temperature demonstration failed: {e}\")\n",
        "\n",
        "def temperature_generation_comparison(prompt):\n",
        "    \"\"\"\n",
        "    Compare actual text generation with different temperatures.\n",
        "\n",
        "    Purpose:\n",
        "        Show how temperature affects the style and variety of generated text\n",
        "        in practice.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text to continue\n",
        "\n",
        "    Expected Output:\n",
        "        Low temp: More repetitive, safe, predictable\n",
        "        Medium temp: Balanced variety and coherence\n",
        "        High temp: More diverse, creative, potentially incoherent\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nTEMPERATURE GENERATION COMPARISON\")\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    temperatures = [0.1, 1.0, 2.0]\n",
        "\n",
        "    for temp in temperatures:\n",
        "        print(f\"\\nTemperature {temp} outputs:\")\n",
        "\n",
        "        messages = [{\"role\": \"user\", \"content\": f\"Continue this text: {prompt}\"}]\n",
        "\n",
        "        for i in range(3):\n",
        "            try:\n",
        "                result = pipe(\n",
        "                    messages,\n",
        "                    max_new_tokens=12,\n",
        "                    temperature=temp,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=pipe.tokenizer.eos_token_id\n",
        "                )[0]['generated_text']\n",
        "                print(f\"   Sample {i+1}: {result}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   Sample {i+1}: Failed: {e}\")\n",
        "\n",
        "# Run temperature demonstrations\n",
        "demonstrate_temperature_effects(\"This luxury watch is\")\n",
        "temperature_generation_comparison(\"This luxury watch is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YvDY5FwM-B_",
        "outputId": "7ddbf8f5-2cb6-4031-8e1d-5d460083ddc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEMPERATURE EFFECTS DEMONSTRATION\n",
            "Prompt: 'This luxury watch is'\n",
            "======================================================================\n",
            "\n",
            "Temperature 0.1:\n",
            "   Distribution sharpness (entropy): 0.00\n",
            "   Top 5 tokens:\n",
            "      a          : 100.0% █████████████████████████\n",
            "      designed   :   0.0% █\n",
            "      made       :   0.0% █\n",
            "      crafted    :   0.0% █\n",
            "      inspired   :   0.0% █\n",
            "   Top 5 probability mass: 100.0%\n",
            "\n",
            "Temperature 1.0:\n",
            "   Distribution sharpness (entropy): 3.09\n",
            "   Top 5 tokens:\n",
            "      a          :  37.5% █████████\n",
            "      designed   :   9.5% ██\n",
            "      made       :   8.4% ██\n",
            "      crafted    :   5.4% █\n",
            "      inspired   :   3.7% █\n",
            "   Top 5 probability mass: 64.5%\n",
            "\n",
            "Temperature 2.0:\n",
            "   Distribution sharpness (entropy): 9.44\n",
            "   Top 5 tokens:\n",
            "      a          :   2.4% █\n",
            "      designed   :   1.2% █\n",
            "      made       :   1.1% █\n",
            "      crafted    :   0.9% █\n",
            "      inspired   :   0.7% █\n",
            "   Top 5 probability mass: 6.3%\n",
            "\n",
            "TEMPERATURE GENERATION COMPARISON\n",
            "Prompt: 'This luxury watch is'\n",
            "--------------------------------------------------\n",
            "\n",
            "Temperature 0.1 outputs:\n",
            "   Sample 1: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a sleek and'}]\n",
            "   Sample 2: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a sleek and'}]\n",
            "   Sample 3: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a sleek and'}]\n",
            "\n",
            "Temperature 1.0 outputs:\n",
            "   Sample 1: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, boasting intricate details and'}]\n",
            "   Sample 2: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, boasting intricate details and'}]\n",
            "   Sample 3: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a sleek and'}]\n",
            "\n",
            "Temperature 2.0 outputs:\n",
            "   Sample 1: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...\"designed to exude elegance and sophistication, boasting a'}]\n",
            "   Sample 2: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a true masterpiece of haute horlogerie, featuring a'}]\n",
            "   Sample 3: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': 'created to epitomize the pinnacle of horological design,'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 4: TRADITIONAL CONTROL METHOD 2 - TOP-K\n",
        "# ============================================================================\n",
        "\n",
        "def demonstrate_top_k_sampling(prompt, k_values=[5, 20, 100]):\n",
        "    \"\"\"\n",
        "    Show how top-k limits vocabulary choices to k most probable tokens.\n",
        "\n",
        "    Purpose:\n",
        "        Demonstrate that top-k sampling reduces vocabulary size by keeping\n",
        "        only the k most probable tokens and zeroing out all others.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text\n",
        "        k_values (list): Different k values to demonstrate\n",
        "\n",
        "    How It Works:\n",
        "        1. Compute probabilities for all tokens\n",
        "        2. Keep only top-k tokens\n",
        "        3. Set all other probabilities to 0\n",
        "        4. Renormalize the k remaining probabilities\n",
        "        5. Sample only from these k tokens\n",
        "\n",
        "    Limitation:\n",
        "        Fixed k doesn't adapt to distribution. Sometimes you want more\n",
        "        options (flat distribution), sometimes fewer (sharp distribution).\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nTOP-K SAMPLING DEMONSTRATION\")\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Get model device and prepare inputs\n",
        "    model_device = get_model_device()\n",
        "    inputs = pipe.tokenizer.encode(prompt, return_tensors='pt').to(model_device)\n",
        "\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            outputs = pipe.model(inputs)\n",
        "            logits = outputs.logits[0, -1]\n",
        "\n",
        "        probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "        for k in k_values:\n",
        "            print(f\"\\nTop-{k} sampling:\")\n",
        "\n",
        "            # Get top-k tokens\n",
        "            top_k_probs, top_k_indices = torch.topk(\n",
        "                probabilities,\n",
        "                min(k, len(probabilities))\n",
        "            )\n",
        "\n",
        "            # Calculate vocabulary statistics\n",
        "            total_vocab_size = len(probabilities)\n",
        "            top_k_mass = top_k_probs.sum().item()\n",
        "\n",
        "            print(f\"   Original vocabulary: {total_vocab_size:,} tokens\")\n",
        "            print(f\"   Filtered vocabulary: {k} tokens ({k/total_vocab_size*100:.1f}%)\")\n",
        "            print(f\"   Probability mass captured: {top_k_mass:.3f}\")\n",
        "\n",
        "            # Show top 5 from the k-filtered distribution\n",
        "            print(\"   Top 5 tokens in filtered vocab:\")\n",
        "            for i in range(min(5, k)):\n",
        "                token = pipe.tokenizer.decode([top_k_indices[i]])\n",
        "                prob = top_k_probs[i].item()\n",
        "                print(f\"     {token:12s}: {prob*100:5.1f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Top-K demonstration failed: {e}\")\n",
        "\n",
        "def top_k_generation_comparison(prompt):\n",
        "    \"\"\"\n",
        "    Compare generation with different k values.\n",
        "\n",
        "    Purpose:\n",
        "        Show how k affects output diversity in practice.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text to continue\n",
        "\n",
        "    Expected Output:\n",
        "        Small k: Very conservative, limited vocabulary\n",
        "        Large k: More diverse, larger vocabulary\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nTOP-K GENERATION COMPARISON\")\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    k_values = [5, 20, 100]\n",
        "    messages = [{\"role\": \"user\", \"content\": f\"Continue this text: {prompt}\"}]\n",
        "\n",
        "    for k in k_values:\n",
        "        print(f\"\\nTop-K = {k}:\")\n",
        "\n",
        "        for i in range(3):\n",
        "            try:\n",
        "                result = pipe(\n",
        "                    messages,\n",
        "                    max_new_tokens=10,\n",
        "                    do_sample=True,\n",
        "                    top_k=k,\n",
        "                    temperature=0.8,\n",
        "                    pad_token_id=pipe.tokenizer.eos_token_id\n",
        "                )[0]['generated_text']\n",
        "                print(f\"   Sample {i+1}: {result}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   Sample {i+1}: Failed: {e}\")\n",
        "\n",
        "# Run top-k demonstrations\n",
        "demonstrate_top_k_sampling(\"This luxury watch is\")\n",
        "top_k_generation_comparison(\"This luxury watch is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlQ5VW2tNEAi",
        "outputId": "7698fb85-587b-43b8-c9b3-feef14bd5995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TOP-K SAMPLING DEMONSTRATION\n",
            "Prompt: 'This luxury watch is'\n",
            "======================================================================\n",
            "\n",
            "Top-5 sampling:\n",
            "   Original vocabulary: 128,256 tokens\n",
            "   Filtered vocabulary: 5 tokens (0.0%)\n",
            "   Probability mass captured: 0.645\n",
            "   Top 5 tokens in filtered vocab:\n",
            "      a          :  37.5%\n",
            "      designed   :   9.5%\n",
            "      made       :   8.4%\n",
            "      crafted    :   5.4%\n",
            "      inspired   :   3.7%\n",
            "\n",
            "Top-20 sampling:\n",
            "   Original vocabulary: 128,256 tokens\n",
            "   Filtered vocabulary: 20 tokens (0.0%)\n",
            "   Probability mass captured: 0.855\n",
            "   Top 5 tokens in filtered vocab:\n",
            "      a          :  37.5%\n",
            "      designed   :   9.5%\n",
            "      made       :   8.4%\n",
            "      crafted    :   5.4%\n",
            "      inspired   :   3.7%\n",
            "\n",
            "Top-100 sampling:\n",
            "   Original vocabulary: 128,256 tokens\n",
            "   Filtered vocabulary: 100 tokens (0.1%)\n",
            "   Probability mass captured: 0.941\n",
            "   Top 5 tokens in filtered vocab:\n",
            "      a          :  37.5%\n",
            "      designed   :   9.5%\n",
            "      made       :   8.4%\n",
            "      crafted    :   5.4%\n",
            "      inspired   :   3.7%\n",
            "\n",
            "TOP-K GENERATION COMPARISON\n",
            "Prompt: 'This luxury watch is'\n",
            "--------------------------------------------------\n",
            "\n",
            "Top-K = 5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Sample 1: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a'}]\n",
            "   Sample 2: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, boasting an'}]\n",
            "   Sample 3: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horology, featuring a sleek'}]\n",
            "\n",
            "Top-K = 20:\n",
            "   Sample 1: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': 'a masterpiece of horological craftsmanship, combining cutting-edge'}]\n",
            "   Sample 2: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, boasting a'}]\n",
            "   Sample 3: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horology, featuring a sleek'}]\n",
            "\n",
            "Top-K = 100:\n",
            "   Sample 1: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a'}]\n",
            "   Sample 2: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a'}]\n",
            "   Sample 3: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 5: TRADITIONAL CONTROL METHOD 3 - TOP-P (NUCLEUS)\n",
        "# ============================================================================\n",
        "\n",
        "def demonstrate_nucleus_sampling(prompt, p_values=[0.5, 0.8, 0.95]):\n",
        "    \"\"\"\n",
        "    Show how nucleus sampling adapts vocabulary size to distribution shape.\n",
        "\n",
        "    Purpose:\n",
        "        Demonstrate that top-p (nucleus sampling) automatically adjusts\n",
        "        vocabulary size based on how concentrated the probability is.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text\n",
        "        p_values (list): Different p values to demonstrate\n",
        "\n",
        "    How It Works:\n",
        "        1. Compute probabilities for all tokens\n",
        "        2. Sort tokens by probability (descending)\n",
        "        3. Keep smallest set where cumulative probability >= p\n",
        "        4. This is the \"nucleus\" - sample only from these tokens\n",
        "\n",
        "    Advantage over Top-K:\n",
        "        Adapts to distribution shape:\n",
        "        - Sharp distribution (clear winner): Keeps ~5-10 tokens\n",
        "        - Flat distribution (many options): Keeps ~50-100 tokens\n",
        "\n",
        "    Limitation:\n",
        "        Still probabilistic. Can't guarantee specific tokens never appear.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nNUCLEUS SAMPLING DEMONSTRATION\")\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Get model device and prepare inputs\n",
        "    model_device = get_model_device()\n",
        "    inputs = pipe.tokenizer.encode(prompt, return_tensors='pt').to(model_device)\n",
        "\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            outputs = pipe.model(inputs)\n",
        "            logits = outputs.logits[0, -1]\n",
        "\n",
        "        probabilities = torch.softmax(logits, dim=-1)\n",
        "        sorted_probs, sorted_indices = torch.sort(probabilities, descending=True)\n",
        "\n",
        "        for p in p_values:\n",
        "            print(f\"\\nTop-P = {p} (Nucleus sampling):\")\n",
        "\n",
        "            # Find nucleus cutoff: smallest set with cumulative prob >= p\n",
        "            cumsum = torch.cumsum(sorted_probs, dim=0)\n",
        "            nucleus_size = (cumsum <= p).sum().item() + 1  # +1 includes cutoff\n",
        "\n",
        "            nucleus_probs = sorted_probs[:nucleus_size]\n",
        "            nucleus_indices = sorted_indices[:nucleus_size]\n",
        "\n",
        "            # Calculate nucleus statistics\n",
        "            nucleus_mass = nucleus_probs.sum().item()\n",
        "            total_vocab = len(probabilities)\n",
        "\n",
        "            print(f\"   Nucleus size: {nucleus_size} tokens \"\n",
        "                  f\"({nucleus_size/total_vocab*100:.2f}% of vocab)\")\n",
        "            print(f\"   Probability mass: {nucleus_mass:.3f}\")\n",
        "\n",
        "            # Characterize distribution\n",
        "            if nucleus_size < 50:\n",
        "                char = \"Sharp distribution (confident prediction)\"\n",
        "            else:\n",
        "                char = \"Flat distribution (many plausible options)\"\n",
        "            print(f\"   Adaptation: {char}\")\n",
        "\n",
        "            # Show top tokens in nucleus\n",
        "            print(\"   Top 5 tokens in nucleus:\")\n",
        "            for i in range(min(5, nucleus_size)):\n",
        "                token = pipe.tokenizer.decode([nucleus_indices[i]])\n",
        "                prob = nucleus_probs[i].item()\n",
        "                print(f\"     {token:12s}: {prob*100:5.1f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Nucleus sampling demonstration failed: {e}\")\n",
        "\n",
        "def compare_top_k_vs_top_p(prompt):\n",
        "    \"\"\"\n",
        "    Direct comparison of top-k vs top-p sampling in generation.\n",
        "\n",
        "    Purpose:\n",
        "        Show the practical difference between fixed vocabulary (top-k)\n",
        "        and adaptive vocabulary (top-p).\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text to continue\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nTOP-K vs TOP-P COMPARISON\")\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": f\"Continue this text: {prompt}\"}]\n",
        "\n",
        "    # Top-K sampling (fixed vocabulary)\n",
        "    print(\"\\nTop-K = 20 (fixed vocabulary):\")\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            result = pipe(\n",
        "                messages,\n",
        "                max_new_tokens=10,\n",
        "                top_k=20,\n",
        "                temperature=0.8,\n",
        "                pad_token_id=pipe.tokenizer.eos_token_id\n",
        "            )[0]['generated_text']\n",
        "            print(f\"   Sample {i+1}: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   Sample {i+1}: Failed: {e}\")\n",
        "\n",
        "    # Top-P sampling (adaptive vocabulary)\n",
        "    print(\"\\nTop-P = 0.8 (adaptive vocabulary):\")\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            result = pipe(\n",
        "                messages,\n",
        "                max_new_tokens=10,\n",
        "                top_p=0.8,\n",
        "                temperature=0.8,\n",
        "                pad_token_id=pipe.tokenizer.eos_token_id\n",
        "            )[0]['generated_text']\n",
        "            print(f\"   Sample {i+1}: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   Sample {i+1}: Failed: {e}\")\n",
        "\n",
        "# Run nucleus sampling demonstrations\n",
        "demonstrate_nucleus_sampling(\"This luxury watch is\")\n",
        "compare_top_k_vs_top_p(\"This luxury watch is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTz2jVuzNIcP",
        "outputId": "b19b64f5-40ce-4acf-99be-3ece2a8896d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NUCLEUS SAMPLING DEMONSTRATION\n",
            "Prompt: 'This luxury watch is'\n",
            "======================================================================\n",
            "\n",
            "Top-P = 0.5 (Nucleus sampling):\n",
            "   Nucleus size: 3 tokens (0.00% of vocab)\n",
            "   Probability mass: 0.555\n",
            "   Adaptation: Sharp distribution (confident prediction)\n",
            "   Top 5 tokens in nucleus:\n",
            "      a          :  37.5%\n",
            "      designed   :   9.5%\n",
            "      made       :   8.4%\n",
            "\n",
            "Top-P = 0.8 (Nucleus sampling):\n",
            "   Nucleus size: 13 tokens (0.01% of vocab)\n",
            "   Probability mass: 0.805\n",
            "   Adaptation: Sharp distribution (confident prediction)\n",
            "   Top 5 tokens in nucleus:\n",
            "      a          :  37.5%\n",
            "      designed   :   9.5%\n",
            "      made       :   8.4%\n",
            "      crafted    :   5.4%\n",
            "      inspired   :   3.7%\n",
            "\n",
            "Top-P = 0.95 (Nucleus sampling):\n",
            "   Nucleus size: 91 tokens (0.07% of vocab)\n",
            "   Probability mass: 0.938\n",
            "   Adaptation: Flat distribution (many plausible options)\n",
            "   Top 5 tokens in nucleus:\n",
            "      a          :  37.5%\n",
            "      designed   :   9.5%\n",
            "      made       :   8.4%\n",
            "      crafted    :   5.4%\n",
            "      inspired   :   3.7%\n",
            "\n",
            "TOP-K vs TOP-P COMPARISON\n",
            "Prompt: 'This luxury watch is'\n",
            "------------------------------------------------------------\n",
            "\n",
            "Top-K = 20 (fixed vocabulary):\n",
            "   Sample 1: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a'}]\n",
            "   Sample 2: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': 'a masterpiece of horology, featuring a sleek and'}]\n",
            "   Sample 3: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, combining intricate'}]\n",
            "\n",
            "Top-P = 0.8 (adaptive vocabulary):\n",
            "   Sample 1: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horology, featuring a sleek'}]\n",
            "   Sample 2: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, boasting a'}]\n",
            "   Sample 3: [{'role': 'user', 'content': 'Continue this text: This luxury watch is'}, {'role': 'assistant', 'content': '...a masterpiece of horological engineering, featuring a'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 6: THE LIMITATION - WHY TRADITIONAL METHODS FAIL\n",
        "# ============================================================================\n",
        "\n",
        "def demonstrate_control_limitations_simple():\n",
        "    \"\"\"\n",
        "    Demonstrate the fundamental limitation of probabilistic controls.\n",
        "\n",
        "    Purpose:\n",
        "        Show that temperature/top-k/top-p control HOW we sample, but cannot\n",
        "        guarantee WHAT gets sampled. If a token has any probability > 0,\n",
        "        it can eventually be selected.\n",
        "\n",
        "    Key Insight:\n",
        "        Over thousands of generations, even 0.1% probability events\n",
        "        will occur. You can reduce violations, but not eliminate them.\n",
        "\n",
        "    Expected Output:\n",
        "        Shows that problematic words have non-zero probability even\n",
        "        in conservative settings.\n",
        "\n",
        "    Business Impact:\n",
        "        For brand compliance, legal requirements, or safety - you need\n",
        "        guarantees, not just reduced probability.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nTRADITIONAL CONTROL LIMITATIONS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    problematic_words = ['cheap', 'affordable', 'budget', 'basic', 'standard']\n",
        "\n",
        "    print(\"The core problem with traditional sampling methods:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Explain the theoretical issue\n",
        "    print(\"THEORETICAL ISSUE:\")\n",
        "    print(\"   • Temperature/Top-K/Top-P control HOW the AI chooses\")\n",
        "    print(\"   • But they can't control WHAT the AI can choose FROM\")\n",
        "    print(\"   • If 'cheap' has 5% probability, it might still get selected\")\n",
        "    print(\"   • Over thousands of generations, violations are inevitable\")\n",
        "\n",
        "    # Demonstrate with actual probabilities\n",
        "    try:\n",
        "        print(f\"\\nPRACTICAL DEMONSTRATION:\")\n",
        "\n",
        "        # Get raw probabilities to show the issue\n",
        "        test_prompt = \"This luxury watch is\"\n",
        "        model_device = get_model_device()\n",
        "        inputs = pipe.tokenizer.encode(test_prompt, return_tensors='pt').to(model_device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = pipe.model(inputs)\n",
        "            logits = outputs.logits[0, -1]\n",
        "\n",
        "        probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "        # Check if problematic words have non-zero probability\n",
        "        problematic_found = False\n",
        "        print(f\"   Checking if problematic words have non-zero probability...\")\n",
        "\n",
        "        for word in problematic_words:\n",
        "            # Tokenize with leading space (important!)\n",
        "            word_tokens = pipe.tokenizer.encode(f\" {word}\", add_special_tokens=False)\n",
        "            if word_tokens:\n",
        "                word_token_id = word_tokens[0]\n",
        "                if word_token_id < len(probabilities):\n",
        "                    word_prob = probabilities[word_token_id].item()\n",
        "                    if word_prob > 1e-6:  # Non-negligible probability\n",
        "                        print(f\"   ❌ '{word}' has {word_prob*100:.3f}% probability\")\n",
        "                        problematic_found = True\n",
        "\n",
        "        if problematic_found:\n",
        "            print(f\"\\n   💡 Even with conservative sampling, these words could appear!\")\n",
        "            print(f\"   💡 Over 1000 generations, you'd expect multiple violations\")\n",
        "        else:\n",
        "            print(f\"\\n   ✅ No problematic words found in top probabilities\")\n",
        "            print(f\"   (But this could change with different prompts)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   Demonstration failed: {e}\")\n",
        "\n",
        "    print(f\"\\nSOLUTION PREVIEW:\")\n",
        "    print(f\"   Logit masking will set problematic word probabilities to 0%\")\n",
        "    print(f\"   Making it IMPOSSIBLE for the AI to select them\")\n",
        "    print(f\"   This guarantees 100% compliance with business rules\")\n",
        "\n",
        "# Demonstrate the limitation\n",
        "demonstrate_control_limitations_simple()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oILlG3T5NMx-",
        "outputId": "bff9f60d-92e3-40b2-fd7a-3c55d958001f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRADITIONAL CONTROL LIMITATIONS\n",
            "======================================================================\n",
            "The core problem with traditional sampling methods:\n",
            "--------------------------------------------------\n",
            "THEORETICAL ISSUE:\n",
            "   • Temperature/Top-K/Top-P control HOW the AI chooses\n",
            "   • But they can't control WHAT the AI can choose FROM\n",
            "   • If 'cheap' has 5% probability, it might still get selected\n",
            "   • Over thousands of generations, violations are inevitable\n",
            "\n",
            "PRACTICAL DEMONSTRATION:\n",
            "   Checking if problematic words have non-zero probability...\n",
            "   ❌ 'affordable' has 0.003% probability\n",
            "   ❌ 'budget' has 0.000% probability\n",
            "   ❌ 'basic' has 0.000% probability\n",
            "   ❌ 'standard' has 0.001% probability\n",
            "\n",
            "   💡 Even with conservative sampling, these words could appear!\n",
            "   💡 Over 1000 generations, you'd expect multiple violations\n",
            "\n",
            "SOLUTION PREVIEW:\n",
            "   Logit masking will set problematic word probabilities to 0%\n",
            "   Making it IMPOSSIBLE for the AI to select them\n",
            "   This guarantees 100% compliance with business rules\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 7: THE SOLUTION - LOGIT MASKING\n",
        "# ============================================================================\n",
        "\n",
        "class RobustBrandAwareLogitsProcessor(LogitsProcessor):\n",
        "    \"\"\"\n",
        "    Production-ready logits processor for guaranteed vocabulary compliance.\n",
        "\n",
        "    Purpose:\n",
        "        Enforce hard constraints on vocabulary by modifying logits before\n",
        "        sampling. This makes violations literally impossible, not just unlikely.\n",
        "\n",
        "    How It Works:\n",
        "        1. Called at each generation step BEFORE sampling\n",
        "        2. Decodes current beam sequences to readable text\n",
        "        3. Scores each sequence: +1 for premium words, -1 for budget words\n",
        "        4. Identifies best-scoring sequence(s)\n",
        "        5. Heavily penalizes logits of lower-scoring sequences\n",
        "        6. Result: Only best-scoring paths can continue\n",
        "\n",
        "    Attributes:\n",
        "        tokenizer: HuggingFace tokenizer for decoding\n",
        "        premium_words (set): Words that increase score\n",
        "        budget_words (set): Words that decrease score\n",
        "        penalty_strength (float): Penalty magnitude (default: 10000)\n",
        "        verbose (bool): Enable debug logging\n",
        "        step_count (int): Track generation steps\n",
        "        device (torch.device): Automatically detected device\n",
        "\n",
        "    Use Cases:\n",
        "        - Brand voice enforcement (premium vs budget language)\n",
        "        - Legal compliance (required/forbidden terms)\n",
        "        - Content safety (block inappropriate content)\n",
        "        - Domain expertise (require technical terminology)\n",
        "        - Format enforcement (structured output)\n",
        "\n",
        "    Example:\n",
        "        >>> processor = RobustBrandAwareLogitsProcessor(\n",
        "        ...     tokenizer,\n",
        "        ...     premium_words={'luxury', 'premium'},\n",
        "        ...     budget_words={'cheap', 'affordable'}\n",
        "        ... )\n",
        "        >>> output = model.generate(\n",
        "        ...     input_ids,\n",
        "        ...     logits_processor=[processor],\n",
        "        ...     num_beams=5\n",
        "        ... )\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer, premium_words, budget_words,\n",
        "                 penalty_strength=10000.0, verbose=False):\n",
        "        \"\"\"\n",
        "        Initialize the logits processor with vocabulary constraints.\n",
        "\n",
        "        Args:\n",
        "            tokenizer: HuggingFace tokenizer\n",
        "            premium_words (set/list): Words that increase compliance score\n",
        "            budget_words (set/list): Words that decrease compliance score\n",
        "            penalty_strength (float): Magnitude of penalty for low-scoring sequences\n",
        "            verbose (bool): Enable detailed logging for debugging\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.premium_words = set(word.lower() for word in premium_words)\n",
        "        self.budget_words = set(word.lower() for word in budget_words)\n",
        "        self.penalty_strength = penalty_strength\n",
        "        self.verbose = verbose\n",
        "        self.step_count = 0\n",
        "        self.device = None  # Will be detected from input tensors\n",
        "\n",
        "        # Print initialization summary\n",
        "        print(f\"RobustBrandAware Processor initialized:\")\n",
        "        print(f\"   ✅ Premium words: {len(self.premium_words)}\")\n",
        "        print(f\"   ❌ Budget words: {len(self.budget_words)}\")\n",
        "        print(f\"   🔧 Penalty strength: {penalty_strength}\")\n",
        "        print(f\"   📊 Verbose mode: {verbose}\")\n",
        "\n",
        "    def _detect_device(self, tensor):\n",
        "        \"\"\"\n",
        "        Dynamically detect and cache device from input tensors.\n",
        "\n",
        "        Purpose:\n",
        "            Avoid device mismatch errors by detecting device once\n",
        "            and reusing it for all tensor operations.\n",
        "\n",
        "        Args:\n",
        "            tensor: Any torch tensor from the generation process\n",
        "\n",
        "        Returns:\n",
        "            torch.device: Detected device (cuda:0 or cpu)\n",
        "        \"\"\"\n",
        "        if self.device is None:\n",
        "            self.device = tensor.device\n",
        "            if self.verbose:\n",
        "                print(f\"   📍 Detected device: {self.device}\")\n",
        "        return self.device\n",
        "\n",
        "    def evaluate_brand_compliance(self, text):\n",
        "        \"\"\"\n",
        "        Score text based on premium vs budget word usage.\n",
        "\n",
        "        Purpose:\n",
        "            Quantify how well text aligns with brand guidelines.\n",
        "\n",
        "        Args:\n",
        "            text (str): Generated text to score\n",
        "\n",
        "        Returns:\n",
        "            int: Score = (premium words count) - (budget words count)\n",
        "                 Higher is better\n",
        "\n",
        "        Examples:\n",
        "            \"luxury premium watch\" -> +2 (2 premium, 0 budget)\n",
        "            \"cheap affordable watch\" -> -2 (0 premium, 2 budget)\n",
        "            \"luxury affordable watch\" -> 0 (1 premium, 1 budget)\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return 0\n",
        "\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Count premium words\n",
        "        premium_count = sum(1 for word in self.premium_words\n",
        "                          if word in text_lower)\n",
        "\n",
        "        # Count budget words\n",
        "        budget_count = sum(1 for word in self.budget_words\n",
        "                         if word in text_lower)\n",
        "\n",
        "        # Score: premium is good, budget is bad\n",
        "        return premium_count - budget_count\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        \"\"\"\n",
        "        Main logit masking logic - called at every generation step.\n",
        "\n",
        "        Purpose:\n",
        "            Modify logits to enforce vocabulary constraints before sampling.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Current sequence IDs for all beams [batch_size, seq_len]\n",
        "            scores: Current logits for next token [batch_size, vocab_size]\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Modified logits with penalties applied\n",
        "\n",
        "        Process:\n",
        "            1. Decode all beam sequences to text\n",
        "            2. Score each sequence for brand compliance\n",
        "            3. Find best score among all beams\n",
        "            4. Penalize beams that don't match best score\n",
        "            5. Return modified logits\n",
        "\n",
        "        Result:\n",
        "            Only highest-scoring sequences can continue generation.\n",
        "            Lower-scoring sequences are effectively eliminated.\n",
        "        \"\"\"\n",
        "        self.step_count += 1\n",
        "\n",
        "        try:\n",
        "            # Detect and adapt to device\n",
        "            device = self._detect_device(scores)\n",
        "\n",
        "            # Clone scores to avoid modifying original\n",
        "            output_scores = scores.clone()\n",
        "\n",
        "            # Evaluate each sequence in the current batch/beams\n",
        "            sequence_scores = []\n",
        "            sequence_texts = []\n",
        "\n",
        "            for seq_idx, sequence in enumerate(input_ids):\n",
        "                try:\n",
        "                    # Move sequence to CPU for decoding (tokenizer works on CPU)\n",
        "                    if sequence.device != torch.device('cpu'):\n",
        "                        sequence_cpu = sequence.cpu()\n",
        "                    else:\n",
        "                        sequence_cpu = sequence\n",
        "\n",
        "                    # Decode current sequence to readable text\n",
        "                    decoded_text = self.tokenizer.decode(\n",
        "                        sequence_cpu,\n",
        "                        skip_special_tokens=True\n",
        "                    )\n",
        "                    sequence_texts.append(decoded_text)\n",
        "\n",
        "                    # Score this sequence for brand compliance\n",
        "                    compliance_score = self.evaluate_brand_compliance(decoded_text)\n",
        "                    sequence_scores.append(compliance_score)\n",
        "\n",
        "                except Exception as decode_error:\n",
        "                    # Graceful handling of decode errors\n",
        "                    if self.verbose:\n",
        "                        print(f\"   ⚠️ Decode error for sequence {seq_idx}: {decode_error}\")\n",
        "                    sequence_scores.append(-999)  # Very low score for errors\n",
        "                    sequence_texts.append(\"[DECODE_ERROR]\")\n",
        "\n",
        "            # Find the best compliance score\n",
        "            if sequence_scores:\n",
        "                max_score = max(sequence_scores)\n",
        "            else:\n",
        "                if self.verbose:\n",
        "                    print(f\"   ⚠️ No valid sequences to evaluate\")\n",
        "                return output_scores\n",
        "\n",
        "            # Mask out sequences that don't meet the maximum standard\n",
        "            masked_count = 0\n",
        "            for seq_idx, score in enumerate(sequence_scores):\n",
        "                if score < max_score:\n",
        "                    # Set all next-token logits for this sequence to very negative\n",
        "                    # This makes these sequences impossible to select\n",
        "                    penalty = torch.full_like(\n",
        "                        output_scores[seq_idx],\n",
        "                        -self.penalty_strength\n",
        "                    )\n",
        "                    output_scores[seq_idx] = penalty\n",
        "                    masked_count += 1\n",
        "\n",
        "            # Optional verbose logging (first few steps only to avoid spam)\n",
        "            if self.verbose and self.step_count <= 3:\n",
        "                print(f\"\\n📊 Logit Masking Step {self.step_count} (Device: {device}):\")\n",
        "                for i, (text, score) in enumerate(zip(sequence_texts, sequence_scores)):\n",
        "                    status = \"✅ KEPT\" if score == max_score else \"❌ MASKED\"\n",
        "                    # Show last 50 chars to see current generation progress\n",
        "                    display_text = text[-50:] if len(text) > 50 else text\n",
        "                    print(f\"   Seq {i+1}: {status} (score: {score:+d}) - '...{display_text}'\")\n",
        "\n",
        "                kept_count = len(sequence_scores) - masked_count\n",
        "                print(f\"   📊 Result: Kept {kept_count}, masked {masked_count} sequences\")\n",
        "\n",
        "            return output_scores\n",
        "\n",
        "        except Exception as e:\n",
        "            # Ultimate fallback - return original scores if anything fails\n",
        "            if self.verbose:\n",
        "                print(f\"❌ LogitsProcessor error: {e}\")\n",
        "            return scores\n",
        "\n",
        "# ============================================================================\n",
        "# VOCABULARY DEFINITIONS\n",
        "# ============================================================================\n",
        "\n",
        "# Define comprehensive business vocabulary\n",
        "PREMIUM_WORDS = {\n",
        "    # Luxury descriptors\n",
        "    'luxury', 'premium', 'exceptional', 'sophisticated', 'exquisite',\n",
        "    'masterpiece', 'artisan', 'handcrafted', 'precision', 'heritage',\n",
        "    'exclusive', 'prestige', 'refined', 'elegant', 'superior',\n",
        "\n",
        "    # Innovation and quality\n",
        "    'innovative', 'advanced', 'professional', 'outstanding', 'remarkable',\n",
        "    'distinguished', 'prestigious', 'world-class', 'finest', 'ultimate'\n",
        "}\n",
        "\n",
        "BUDGET_WORDS = {\n",
        "    # Price-focused terms\n",
        "    'cheap', 'affordable', 'budget', 'discount', 'value', 'deal', 'bargain',\n",
        "    'low-cost', 'inexpensive', 'economical', 'reasonable',\n",
        "\n",
        "    # Quality diminishers\n",
        "    'basic', 'standard', 'ordinary', 'common', 'typical', 'average',\n",
        "    'generic', 'simple', 'plain', 'entry-level', 'mass-produced'\n",
        "}\n",
        "\n",
        "# ============================================================================\n",
        "# INITIALIZE BRAND GUARDIAN\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n🛡️ INITIALIZING ROBUST BRAND GUARDIAN\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "brand_guardian = RobustBrandAwareLogitsProcessor(\n",
        "    pipe.tokenizer,\n",
        "    PREMIUM_WORDS,\n",
        "    BUDGET_WORDS,\n",
        "    penalty_strength=8000.0,  # Slightly lower for stability\n",
        "    verbose=True  # Enable detailed logging for first 3 steps\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# HELPER FUNCTIONS FOR CLEAN DEMONSTRATION\n",
        "# ============================================================================\n",
        "\n",
        "def extract_assistant_content_only(pipeline_output):\n",
        "    \"\"\"\n",
        "    Extract only the assistant's response from pipeline output.\n",
        "\n",
        "    Purpose:\n",
        "        Clean up pipeline output to get just the generated text without\n",
        "        conversation formatting or metadata.\n",
        "\n",
        "    Args:\n",
        "        pipeline_output: Raw output from pipeline\n",
        "\n",
        "    Returns:\n",
        "        str: Clean generated text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if isinstance(pipeline_output, list) and len(pipeline_output) > 0:\n",
        "            first_item = pipeline_output[0]\n",
        "            if isinstance(first_item, dict) and 'generated_text' in first_item:\n",
        "                conversation = first_item['generated_text']\n",
        "\n",
        "                # If conversation is a list of messages, extract assistant's content\n",
        "                if isinstance(conversation, list):\n",
        "                    for message in conversation:\n",
        "                        if isinstance(message, dict) and message.get('role') == 'assistant':\n",
        "                            return message.get('content', '').strip()\n",
        "\n",
        "                # Fallback to string conversion\n",
        "                elif isinstance(conversation, str):\n",
        "                    return conversation.strip()\n",
        "\n",
        "        return str(pipeline_output).strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return str(pipeline_output).strip()\n",
        "\n",
        "def analyze_word_usage(text, premium_words, budget_words):\n",
        "    \"\"\"\n",
        "    Analyze premium and budget word usage in generated text.\n",
        "\n",
        "    Purpose:\n",
        "        Quantify vocabulary compliance for evaluation and reporting.\n",
        "\n",
        "    Args:\n",
        "        text (str): Generated text to analyze\n",
        "        premium_words (set): Premium vocabulary\n",
        "        budget_words (set): Budget vocabulary\n",
        "\n",
        "    Returns:\n",
        "        dict: Analysis with keys:\n",
        "            - premium_words: List of premium words found\n",
        "            - budget_words: List of budget words found\n",
        "            - score: Net score (premium - budget)\n",
        "            - total_premium: Count of premium words\n",
        "            - total_budget: Count of budget words\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Find premium words used\n",
        "    premium_found = []\n",
        "    for word in premium_words:\n",
        "        if word in text_lower:\n",
        "            count = text_lower.count(word)\n",
        "            premium_found.append(f\"{word} ({count}x)\" if count > 1 else word)\n",
        "\n",
        "    # Find budget words used\n",
        "    budget_found = []\n",
        "    for word in budget_words:\n",
        "        if word in text_lower:\n",
        "            count = text_lower.count(word)\n",
        "            budget_found.append(f\"{word} ({count}x)\" if count > 1 else word)\n",
        "\n",
        "    # Calculate score\n",
        "    score = len([w for w in premium_words if w in text_lower]) - \\\n",
        "            len([w for w in budget_words if w in text_lower])\n",
        "\n",
        "    return {\n",
        "        'premium_words': premium_found,\n",
        "        'budget_words': budget_found,\n",
        "        'score': score,\n",
        "        'total_premium': len(premium_found),\n",
        "        'total_budget': len(budget_found)\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w7tRrX5NesY",
        "outputId": "da833bed-a352-4da9-cb1d-b9e007f7df42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🛡️ INITIALIZING ROBUST BRAND GUARDIAN\n",
            "============================================================\n",
            "RobustBrandAware Processor initialized:\n",
            "   ✅ Premium words: 25\n",
            "   ❌ Budget words: 22\n",
            "   🔧 Penalty strength: 8000.0\n",
            "   📊 Verbose mode: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PART 8: DEMONSTRATION - BEFORE AND AFTER\n",
        "# ============================================================================\n",
        "\n",
        "def clean_logit_masking_demonstration(product_name):\n",
        "    \"\"\"\n",
        "    Clean demonstration of logit masking effectiveness.\n",
        "\n",
        "    Purpose:\n",
        "        Show clear before/after comparison of generation with and without\n",
        "        logit masking constraints.\n",
        "\n",
        "    Args:\n",
        "        product_name (str): Product to generate description for\n",
        "\n",
        "    Returns:\n",
        "        dict: Results with baseline and controlled analysis\n",
        "\n",
        "    Expected Output:\n",
        "        Baseline: May contain budget words, lower brand score\n",
        "        Controlled: Only premium words, higher brand score\n",
        "\n",
        "    Key Metrics:\n",
        "        - Brand Score: (premium words) - (budget words)\n",
        "        - Premium Word Count\n",
        "        - Budget Word Count\n",
        "        - Improvement: Change in score\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*80)\n",
        "    print(f\"LOGIT MASKING DEMONSTRATION: {product_name.upper()}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Create professional prompt\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional product marketing expert. Write compelling product descriptions.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Write a professional product description for this {product_name}. Focus on premium quality and craftsmanship.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Standard generation parameters\n",
        "    gen_params = {\n",
        "        \"max_new_tokens\": 80,\n",
        "        \"do_sample\": True,\n",
        "        \"temperature\": 0.8,\n",
        "        \"num_beams\": 5,\n",
        "        \"early_stopping\": True,\n",
        "        \"pad_token_id\": pipe.tokenizer.eos_token_id\n",
        "    }\n",
        "\n",
        "    # ========================================\n",
        "    # BASELINE: Generate WITHOUT control\n",
        "    # ========================================\n",
        "    print(f\"\\n📝 BASELINE GENERATION (No Control)\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        baseline_output = pipe(messages, **gen_params)\n",
        "        baseline_text = extract_assistant_content_only(baseline_output)\n",
        "        baseline_analysis = analyze_word_usage(baseline_text, PREMIUM_WORDS, BUDGET_WORDS)\n",
        "\n",
        "        print(f\"Generated Text:\")\n",
        "        print(f'\"{baseline_text}\"')\n",
        "        print(f\"\\nWord Analysis:\")\n",
        "        print(f\"  ✅ Premium words: {', '.join(baseline_analysis['premium_words']) if baseline_analysis['premium_words'] else 'None'}\")\n",
        "        print(f\"  ❌ Budget words:  {', '.join(baseline_analysis['budget_words']) if baseline_analysis['budget_words'] else 'None'}\")\n",
        "        print(f\"  📊 Brand Score: {baseline_analysis['score']:+d} \"\n",
        "              f\"({baseline_analysis['total_premium']} premium - \"\n",
        "              f\"{baseline_analysis['total_budget']} budget)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Baseline generation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # ========================================\n",
        "    # CONTROLLED: Generate WITH logit masking\n",
        "    # ========================================\n",
        "    print(f\"\\n🎛️ CONTROLLED GENERATION (With Logit Masking)\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Create processor (non-verbose for clean output)\n",
        "        processor = RobustBrandAwareLogitsProcessor(\n",
        "            pipe.tokenizer,\n",
        "            PREMIUM_WORDS,\n",
        "            BUDGET_WORDS,\n",
        "            verbose=False  # Disable logging for clean demo\n",
        "        )\n",
        "\n",
        "        # Add processor to generation parameters\n",
        "        controlled_params = gen_params.copy()\n",
        "        controlled_params[\"logits_processor\"] = [processor]\n",
        "\n",
        "        controlled_output = pipe(messages, **controlled_params)\n",
        "        controlled_text = extract_assistant_content_only(controlled_output)\n",
        "        controlled_analysis = analyze_word_usage(controlled_text, PREMIUM_WORDS, BUDGET_WORDS)\n",
        "\n",
        "        print(f\"Generated Text:\")\n",
        "        print(f'\"{controlled_text}\"')\n",
        "        print(f\"\\nWord Analysis:\")\n",
        "        print(f\"  ✅ Premium words: {', '.join(controlled_analysis['premium_words']) if controlled_analysis['premium_words'] else 'None'}\")\n",
        "        print(f\"  ❌ Budget words:  {', '.join(controlled_analysis['budget_words']) if controlled_analysis['budget_words'] else 'None'}\")\n",
        "        print(f\"  📊 Brand Score: {controlled_analysis['score']:+d} \"\n",
        "              f\"({controlled_analysis['total_premium']} premium - \"\n",
        "              f\"{controlled_analysis['total_budget']} budget)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Controlled generation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # ========================================\n",
        "    # IMPACT ANALYSIS\n",
        "    # ========================================\n",
        "    improvement = controlled_analysis['score'] - baseline_analysis['score']\n",
        "    premium_increase = controlled_analysis['total_premium'] - baseline_analysis['total_premium']\n",
        "    budget_decrease = baseline_analysis['total_budget'] - controlled_analysis['total_budget']\n",
        "\n",
        "    print(f\"\\n📈 IMPACT ANALYSIS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Brand Score Change:    {baseline_analysis['score']:+d} → \"\n",
        "          f\"{controlled_analysis['score']:+d} ({improvement:+d} points)\")\n",
        "    print(f\"Premium Words:         {baseline_analysis['total_premium']} → \"\n",
        "          f\"{controlled_analysis['total_premium']} ({premium_increase:+d} words)\")\n",
        "    print(f\"Budget Words:          {baseline_analysis['total_budget']} → \"\n",
        "          f\"{controlled_analysis['total_budget']} ({budget_decrease:+d} words)\")\n",
        "\n",
        "    if improvement > 0:\n",
        "        improvement_pct = ((controlled_analysis['score'] - baseline_analysis['score']) /\n",
        "                          max(1, abs(baseline_analysis['score']))) * 100\n",
        "        print(f\"Overall Improvement:   {improvement_pct:+.0f}% more brand-compliant\")\n",
        "\n",
        "    # Key insights\n",
        "    print(f\"\\n🔍 KEY INSIGHTS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # What was promoted\n",
        "    new_premium_words = set(controlled_analysis['premium_words']) - set(baseline_analysis['premium_words'])\n",
        "    if new_premium_words:\n",
        "        print(f\"✅ Promoted words: {', '.join(new_premium_words)}\")\n",
        "\n",
        "    # What was suppressed\n",
        "    suppressed_budget_words = set(baseline_analysis['budget_words']) - set(controlled_analysis['budget_words'])\n",
        "    if suppressed_budget_words:\n",
        "        print(f\"❌ Suppressed words: {', '.join(suppressed_budget_words)}\")\n",
        "\n",
        "    if not new_premium_words and not suppressed_budget_words and improvement > 0:\n",
        "        print(f\"🎯 Enhanced premium word density without suppressing specific terms\")\n",
        "    elif improvement == 0:\n",
        "        print(f\"📊 Baseline was already well-optimized for this product\")\n",
        "\n",
        "    return {\n",
        "        'baseline': baseline_analysis,\n",
        "        'controlled': controlled_analysis,\n",
        "        'improvement': improvement,\n",
        "        'baseline_text': baseline_text,\n",
        "        'controlled_text': controlled_text\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# RUN COMPREHENSIVE DEMONSTRATIONS\n",
        "# ============================================================================\n",
        "\n",
        "def run_comprehensive_clean_demo():\n",
        "    \"\"\"\n",
        "    Run multiple product demonstrations to show consistency.\n",
        "\n",
        "    Purpose:\n",
        "        Demonstrate that logit masking works consistently across\n",
        "        different product categories and contexts.\n",
        "\n",
        "    Returns:\n",
        "        list: Results from all test cases\n",
        "\n",
        "    Expected Output:\n",
        "        Consistent improvement in brand compliance scores across\n",
        "        all product categories.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*80)\n",
        "    print(f\"COMPREHENSIVE LOGIT MASKING ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Testing controlled text generation across multiple luxury product categories\")\n",
        "\n",
        "    test_products = [\n",
        "        \"Swiss luxury watch with leather strap\",\n",
        "        \"Italian leather handbag with gold accents\",\n",
        "        \"premium wireless headphones\",\n",
        "        \"artisan fountain pen with gold nib\"\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    total_improvement = 0\n",
        "\n",
        "    for i, product in enumerate(test_products, 1):\n",
        "        print(f\"\\n{'='*20} TEST {i}/{len(test_products)} {'='*20}\")\n",
        "\n",
        "        result = clean_logit_masking_demonstration(product)\n",
        "\n",
        "        if result:\n",
        "            results.append({\n",
        "                'product': product,\n",
        "                'improvement': result['improvement'],\n",
        "                'baseline_score': result['baseline']['score'],\n",
        "                'controlled_score': result['controlled']['score']\n",
        "            })\n",
        "            total_improvement += result['improvement']\n",
        "\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "    # Summary analysis\n",
        "    if results:\n",
        "        avg_improvement = total_improvement / len(results)\n",
        "        successful_tests = len(results)\n",
        "\n",
        "        print(f\"\\n📊 EXECUTIVE SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Tests Completed:       {successful_tests}/{len(test_products)}\")\n",
        "        print(f\"Average Improvement:   {avg_improvement:+.1f} points\")\n",
        "        print(f\"Total Improvement:     {total_improvement:+d} points\")\n",
        "\n",
        "        # Performance by product\n",
        "        print(f\"\\nPerformance by Product:\")\n",
        "        for result in results:\n",
        "            improvement_indicator = \"🚀\" if result['improvement'] > 0 else \"➖\"\n",
        "            print(f\"  {improvement_indicator} {result['product']:<45} \"\n",
        "                  f\"{result['baseline_score']:+2d} → \"\n",
        "                  f\"{result['controlled_score']:+2d} \"\n",
        "                  f\"({result['improvement']:+d})\")\n",
        "\n",
        "        # Key findings\n",
        "        best_improvement = max(results, key=lambda x: x['improvement'])\n",
        "        print(f\"\\n🏆 Best Performance: {best_improvement['product']} \"\n",
        "              f\"({best_improvement['improvement']:+d} points)\")\n",
        "\n",
        "        print(f\"\\n✅ SUCCESS: Logit masking consistently improves brand compliance\")\n",
        "        print(f\"   Average improvement of {avg_improvement:.1f} points across all categories\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n❌ No successful demonstrations completed\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run the comprehensive demonstration\n",
        "print(\"\\n🎯 RUNNING LOGIT MASKING DEMONSTRATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comprehensive_results = run_comprehensive_clean_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZE0J1D7Npw9",
        "outputId": "83ee33d8-5066-48c1-fe74-34f17a83e58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 RUNNING LOGIT MASKING DEMONSTRATIONS\n",
            "============================================================\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE LOGIT MASKING ANALYSIS\n",
            "================================================================================\n",
            "Testing controlled text generation across multiple luxury product categories\n",
            "\n",
            "==================== TEST 1/4 ====================\n",
            "\n",
            "================================================================================\n",
            "LOGIT MASKING DEMONSTRATION: SWISS LUXURY WATCH WITH LEATHER STRAP\n",
            "================================================================================\n",
            "\n",
            "📝 BASELINE GENERATION (No Control)\n",
            "--------------------------------------------------\n",
            "Generated Text:\n",
            "\"**Introducing the Timeless Masterpiece: Swiss Luxury Watch with Leather Strap**\n",
            "\n",
            "Elevate your style and sophistication with our exquisite Swiss luxury watch, expertly crafted to meet the highest standards of precision and elegance. This masterpiece is a testament to the art of watchmaking, where every detail is meticulously considered to create a truly exceptional timepiece.\n",
            "\n",
            "**Crafted with Precision and Passion**\n",
            "\n",
            "Our Swiss luxury\"\n",
            "\n",
            "Word Analysis:\n",
            "  ✅ Premium words: exquisite, precision (2x), masterpiece (2x), luxury (3x), exceptional\n",
            "  ❌ Budget words:  standard\n",
            "  📊 Brand Score: +4 (5 premium - 1 budget)\n",
            "\n",
            "🎛️ CONTROLLED GENERATION (With Logit Masking)\n",
            "--------------------------------------------------\n",
            "RobustBrandAware Processor initialized:\n",
            "   ✅ Premium words: 25\n",
            "   ❌ Budget words: 22\n",
            "   🔧 Penalty strength: 10000.0\n",
            "   📊 Verbose mode: False\n",
            "Generated Text:\n",
            "\"**Introducing the Masterpiece Timepiece: Swiss Luxury Watch with Leather Strap**\n",
            "\n",
            "Elevate your style and sophistication with our exquisite Swiss luxury watch, handcrafted with exceptional precision and attention to detail. This masterpiece is a testament to the finest traditions of Swiss watchmaking, where tradition meets innovation.\n",
            "\n",
            "**Crafted with the Finest Materials**\n",
            "\n",
            "Our luxury watch features a sturdy and elegant stainless steel case,\"\n",
            "\n",
            "Word Analysis:\n",
            "  ✅ Premium words: exquisite, precision, masterpiece (2x), elegant, finest (2x), luxury (3x), handcrafted, exceptional\n",
            "  ❌ Budget words:  None\n",
            "  📊 Brand Score: +8 (8 premium - 0 budget)\n",
            "\n",
            "📈 IMPACT ANALYSIS\n",
            "--------------------------------------------------\n",
            "Brand Score Change:    +4 → +8 (+4 points)\n",
            "Premium Words:         5 → 8 (+3 words)\n",
            "Budget Words:          1 → 0 (+1 words)\n",
            "Overall Improvement:   +100% more brand-compliant\n",
            "\n",
            "🔍 KEY INSIGHTS\n",
            "--------------------------------------------------\n",
            "✅ Promoted words: finest (2x), elegant, precision, handcrafted\n",
            "❌ Suppressed words: standard\n",
            "============================================================\n",
            "\n",
            "==================== TEST 2/4 ====================\n",
            "\n",
            "================================================================================\n",
            "LOGIT MASKING DEMONSTRATION: ITALIAN LEATHER HANDBAG WITH GOLD ACCENTS\n",
            "================================================================================\n",
            "\n",
            "📝 BASELINE GENERATION (No Control)\n",
            "--------------------------------------------------\n",
            "Generated Text:\n",
            "\"**Introducing the Bella Vita Italian Leather Handbag**\n",
            "\n",
            "Elevate your style with the exquisite Bella Vita Italian Leather Handbag, expertly crafted with the finest Italian leather and adorned with 24-karat gold accents. This luxurious handbag is a testament to the art of traditional Italian craftsmanship, where every detail is meticulously considered to create a truly exceptional piece.\n",
            "\n",
            "**Premium Italian Leather**\n",
            "\n",
            "The Bella Vita\"\n",
            "\n",
            "Word Analysis:\n",
            "  ✅ Premium words: exquisite, finest, premium, exceptional\n",
            "  ❌ Budget words:  None\n",
            "  📊 Brand Score: +4 (4 premium - 0 budget)\n",
            "\n",
            "🎛️ CONTROLLED GENERATION (With Logit Masking)\n",
            "--------------------------------------------------\n",
            "RobustBrandAware Processor initialized:\n",
            "   ✅ Premium words: 25\n",
            "   ❌ Budget words: 22\n",
            "   🔧 Penalty strength: 10000.0\n",
            "   📊 Verbose mode: False\n",
            "Generated Text:\n",
            "\"**Luxury Italian Leather Handbag with Gold Accents**\n",
            "\n",
            "Elevate your style with this exquisite, handcrafted Italian leather handbag, featuring exceptional craftsmanship and premium materials. Made from the finest, full-grain Italian leather, this masterpiece boasts a rich, velvety texture and a sophisticated sheen that exudes refinement.\n",
            "\n",
            "The bag's elegant design is accentuated by 24-karat gold\"\n",
            "\n",
            "Word Analysis:\n",
            "  ✅ Premium words: exquisite, masterpiece, elegant, finest, luxury, sophisticated, handcrafted, premium, exceptional\n",
            "  ❌ Budget words:  None\n",
            "  📊 Brand Score: +9 (9 premium - 0 budget)\n",
            "\n",
            "📈 IMPACT ANALYSIS\n",
            "--------------------------------------------------\n",
            "Brand Score Change:    +4 → +9 (+5 points)\n",
            "Premium Words:         4 → 9 (+5 words)\n",
            "Budget Words:          0 → 0 (+0 words)\n",
            "Overall Improvement:   +125% more brand-compliant\n",
            "\n",
            "🔍 KEY INSIGHTS\n",
            "--------------------------------------------------\n",
            "✅ Promoted words: luxury, sophisticated, handcrafted, elegant, masterpiece\n",
            "============================================================\n",
            "\n",
            "==================== TEST 3/4 ====================\n",
            "\n",
            "================================================================================\n",
            "LOGIT MASKING DEMONSTRATION: PREMIUM WIRELESS HEADPHONES\n",
            "================================================================================\n",
            "\n",
            "📝 BASELINE GENERATION (No Control)\n",
            "--------------------------------------------------\n",
            "Generated Text:\n",
            "\"**Introducing the Aurum Wireless Headphones: Elevate Your Audio Experience**\n",
            "\n",
            "Experience the pinnacle of wireless audio with the Aurum Wireless Headphones, expertly crafted to deliver unparalleled sound quality, comfort, and style. These premium headphones are designed to transport you to a world of immersive audio, where every note, every beat, and every detail comes alive.\n",
            "\n",
            "**Crafted with Precision and Care**\"\n",
            "\n",
            "Word Analysis:\n",
            "  ✅ Premium words: precision, premium\n",
            "  ❌ Budget words:  None\n",
            "  📊 Brand Score: +2 (2 premium - 0 budget)\n",
            "\n",
            "🎛️ CONTROLLED GENERATION (With Logit Masking)\n",
            "--------------------------------------------------\n",
            "RobustBrandAware Processor initialized:\n",
            "   ✅ Premium words: 25\n",
            "   ❌ Budget words: 22\n",
            "   🔧 Penalty strength: 10000.0\n",
            "   📊 Verbose mode: False\n",
            "Generated Text:\n",
            "\"**Introducing Elevé: The Ultimate Luxury Wireless Headphones**\n",
            "\n",
            "Elevé is a masterpiece of engineering and design, crafted with the finest materials and precision to deliver unparalleled sound quality and comfort. These premium wireless headphones are designed for the discerning listener who demands the best, with a focus on exceptional craftsmanship, durability, and innovative features.\n",
            "\n",
            "**Handcrafted with Precision**\n",
            "\n",
            "Each pair of Elevé headphones\"\n",
            "\n",
            "Word Analysis:\n",
            "  ✅ Premium words: innovative, precision (2x), masterpiece, finest, luxury, handcrafted, ultimate, premium, exceptional\n",
            "  ❌ Budget words:  None\n",
            "  📊 Brand Score: +9 (9 premium - 0 budget)\n",
            "\n",
            "📈 IMPACT ANALYSIS\n",
            "--------------------------------------------------\n",
            "Brand Score Change:    +2 → +9 (+7 points)\n",
            "Premium Words:         2 → 9 (+7 words)\n",
            "Budget Words:          0 → 0 (+0 words)\n",
            "Overall Improvement:   +350% more brand-compliant\n",
            "\n",
            "🔍 KEY INSIGHTS\n",
            "--------------------------------------------------\n",
            "✅ Promoted words: finest, luxury, innovative, precision (2x), handcrafted, ultimate, masterpiece, exceptional\n",
            "============================================================\n",
            "\n",
            "==================== TEST 4/4 ====================\n",
            "\n",
            "================================================================================\n",
            "LOGIT MASKING DEMONSTRATION: ARTISAN FOUNTAIN PEN WITH GOLD NIB\n",
            "================================================================================\n",
            "\n",
            "📝 BASELINE GENERATION (No Control)\n",
            "--------------------------------------------------\n",
            "Generated Text:\n",
            "\"**Introducing the Aurum Fountain Pen: A Masterpiece of Timeless Elegance**\n",
            "\n",
            "Experience the art of writing with the Aurum Fountain Pen, a masterpiece of craftsmanship that embodies the essence of luxury and sophistication. This exquisite artisanal pen is handcrafted with the finest materials and attention to detail, ensuring a writing experience that is nothing short of exceptional.\n",
            "\n",
            "The Aurum Fountain Pen boasts a stunning\"\n",
            "\n",
            "Word Analysis:\n",
            "  ✅ Premium words: exquisite, artisan, masterpiece (2x), finest, luxury, handcrafted, exceptional\n",
            "  ❌ Budget words:  None\n",
            "  📊 Brand Score: +7 (7 premium - 0 budget)\n",
            "\n",
            "🎛️ CONTROLLED GENERATION (With Logit Masking)\n",
            "--------------------------------------------------\n",
            "RobustBrandAware Processor initialized:\n",
            "   ✅ Premium words: 25\n",
            "   ❌ Budget words: 22\n",
            "   🔧 Penalty strength: 10000.0\n",
            "   📊 Verbose mode: False\n",
            "Generated Text:\n",
            "\"**Exquisite Artisan Fountain Pen with 24K Gold Nib**\n",
            "\n",
            "Experience the pinnacle of writing luxury with our exceptional handcrafted fountain pen, featuring a stunning 24K gold nib. This masterpiece of precision engineering showcases the finest materials and meticulous attention to detail, elevating the art of writing to new heights.\n",
            "\n",
            "**Crafted with Precision**\n",
            "\n",
            "Each pen is carefully hand-assembled by skilled artisans,\"\n",
            "\n",
            "Word Analysis:\n",
            "  ✅ Premium words: exquisite, artisan (2x), precision (2x), masterpiece, finest, luxury, handcrafted, exceptional\n",
            "  ❌ Budget words:  None\n",
            "  📊 Brand Score: +8 (8 premium - 0 budget)\n",
            "\n",
            "📈 IMPACT ANALYSIS\n",
            "--------------------------------------------------\n",
            "Brand Score Change:    +7 → +8 (+1 points)\n",
            "Premium Words:         7 → 8 (+1 words)\n",
            "Budget Words:          0 → 0 (+0 words)\n",
            "Overall Improvement:   +14% more brand-compliant\n",
            "\n",
            "🔍 KEY INSIGHTS\n",
            "--------------------------------------------------\n",
            "✅ Promoted words: artisan (2x), precision (2x), masterpiece\n",
            "============================================================\n",
            "\n",
            "📊 EXECUTIVE SUMMARY\n",
            "============================================================\n",
            "Tests Completed:       4/4\n",
            "Average Improvement:   +4.2 points\n",
            "Total Improvement:     +17 points\n",
            "\n",
            "Performance by Product:\n",
            "  🚀 Swiss luxury watch with leather strap         +4 → +8 (+4)\n",
            "  🚀 Italian leather handbag with gold accents     +4 → +9 (+5)\n",
            "  🚀 premium wireless headphones                   +2 → +9 (+7)\n",
            "  🚀 artisan fountain pen with gold nib            +7 → +8 (+1)\n",
            "\n",
            "🏆 Best Performance: premium wireless headphones (+7 points)\n",
            "\n",
            "✅ SUCCESS: Logit masking consistently improves brand compliance\n",
            "   Average improvement of 4.2 points across all categories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UgU5rcySNqiT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}